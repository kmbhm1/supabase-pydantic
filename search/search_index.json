{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"api/api-reference/","title":"API Reference","text":""},{"location":"api/api-reference/#database-constants","title":"Database Constants","text":""},{"location":"api/api-reference/#supabase_pydantic.db.constants.DatabaseConnectionType","title":"<code>DatabaseConnectionType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum for database connection types.</p> Source code in <code>src/supabase_pydantic/db/constants.py</code> <pre><code>class DatabaseConnectionType(Enum):\n    \"\"\"Enum for database connection types.\"\"\"\n\n    LOCAL = 'local'\n    DB_URL = 'db_url'\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.constants.DatabaseUserDefinedType","title":"<code>DatabaseUserDefinedType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum for database user defined types.</p> Source code in <code>src/supabase_pydantic/db/constants.py</code> <pre><code>class DatabaseUserDefinedType(str, Enum):\n    \"\"\"Enum for database user defined types.\"\"\"\n\n    DOMAIN = 'DOMAIN'\n    COMPOSITE = 'COMPOSITE'\n    ENUM = 'ENUM'\n    RANGE = 'RANGE'\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.constants.RelationType","title":"<code>RelationType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum for relation types.</p> Source code in <code>src/supabase_pydantic/db/constants.py</code> <pre><code>class RelationType(str, Enum):\n    \"\"\"Enum for relation types.\"\"\"\n\n    ONE_TO_ONE = 'One-to-One'\n    ONE_TO_MANY = 'One-to-Many'\n    MANY_TO_MANY = 'Many-to-Many'\n    MANY_TO_ONE = 'Many-to-One'  # When a table has a foreign key to another table (e.g., File -&gt; Project)\n</code></pre>"},{"location":"api/api-reference/#core-constants","title":"Core Constants","text":""},{"location":"api/api-reference/#supabase_pydantic.core.constants.FrameWorkType","title":"<code>FrameWorkType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum for framework types.</p> Source code in <code>src/supabase_pydantic/core/constants.py</code> <pre><code>class FrameWorkType(Enum):\n    \"\"\"Enum for framework types.\"\"\"\n\n    FASTAPI = 'fastapi'\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.core.constants.OrmType","title":"<code>OrmType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum for file types.</p> Source code in <code>src/supabase_pydantic/core/constants.py</code> <pre><code>class OrmType(Enum):\n    \"\"\"Enum for file types.\"\"\"\n\n    PYDANTIC = 'pydantic'\n    SQLALCHEMY = 'sqlalchemy'\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.core.constants.WriterClassType","title":"<code>WriterClassType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum for writer class types.</p> Source code in <code>src/supabase_pydantic/core/constants.py</code> <pre><code>class WriterClassType(Enum):\n    \"\"\"Enum for writer class types.\"\"\"\n\n    BASE = 'base'  # The main Row model with all fields\n    BASE_WITH_PARENT = 'base_with_parent'\n    PARENT = 'parent'\n    INSERT = 'insert'  # Model for insert operations - auto-generated fields optional\n    UPDATE = 'update'  # Model for update operations - all fields optional\n</code></pre>"},{"location":"api/api-reference/#utility-constants","title":"Utility Constants","text":""},{"location":"api/api-reference/#supabase_pydantic.utils.constants.AppConfig","title":"<code>AppConfig</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration for the Supabase Pydantic tool.</p> Source code in <code>src/supabase_pydantic/utils/constants.py</code> <pre><code>class AppConfig(TypedDict, total=False):\n    \"\"\"Configuration for the Supabase Pydantic tool.\"\"\"\n\n    default_directory: str\n    overwrite_existing_files: bool\n    nullify_base_schema: bool\n    disable_model_prefix_protection: bool\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.utils.constants.ToolConfig","title":"<code>ToolConfig</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration for the Supabase Pydantic tool.</p> Source code in <code>src/supabase_pydantic/utils/constants.py</code> <pre><code>class ToolConfig(TypedDict):\n    \"\"\"Configuration for the Supabase Pydantic tool.\"\"\"\n\n    supabase_pydantic: AppConfig\n</code></pre>"},{"location":"api/api-reference/#database-models","title":"Database Models","text":""},{"location":"api/api-reference/#supabase_pydantic.db.models.ColumnInfo","title":"<code>ColumnInfo</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AsDictParent</code></p> <p>Column information.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>@dataclass\nclass ColumnInfo(AsDictParent):\n    \"\"\"Column information.\"\"\"\n\n    name: str\n    post_gres_datatype: str\n    datatype: str\n    user_defined_values: list[str] | None = field(default_factory=list)\n    unique_partners: list[str] | None = field(default_factory=list)\n    alias: str | None = None\n    default: str | None = None\n    max_length: int | None = None\n    is_nullable: bool | None = True\n    primary: bool = False\n    is_unique: bool = False\n    is_foreign_key: bool = False\n    constraint_definition: str | None = None\n    is_identity: bool = False  # For auto-generated identity columns\n    enum_info: EnumInfo | None = None  # New field for enum metadata\n    array_element_type: str | None = None  # Stores element type for array columns\n    description: str | None = None  # Stores the description of the column\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the column.\"\"\"\n        return f'ColumnInfo({self.name}, {self.post_gres_datatype})'\n\n    @property\n    def has_default(self) -&gt; bool:\n        \"\"\"Check if the column has a default value.\"\"\"\n        return self.default is not None\n\n    @property\n    def is_generated(self) -&gt; bool:\n        \"\"\"Check if the column is auto-generated (identity or serial).\"\"\"\n        return self.is_identity or (self.default is not None and 'nextval' in str(self.default).lower())\n\n    def orm_imports(self, orm_type: OrmType = OrmType.PYDANTIC) -&gt; set[str | None]:\n        \"\"\"Get the unique import statements for a column.\"\"\"\n        imports = set()  # future proofing in case multiple imports are needed\n        if orm_type == OrmType.SQLALCHEMY:\n            i = get_sqlalchemy_type(self.post_gres_datatype, ('Any', 'from sqlalchemy import Column'))[1]\n        else:\n            i = get_pydantic_type(self.post_gres_datatype)[1]\n        imports.add(i)\n        return imports\n\n    def orm_datatype(self, orm_type: OrmType = OrmType.PYDANTIC) -&gt; str:\n        \"\"\"Get the datatype for a column.\"\"\"\n        if orm_type == OrmType.SQLALCHEMY:\n            sql_datatype: str = get_sqlalchemy_type(self.post_gres_datatype)[0]\n            return sql_datatype\n\n        pydantic_datatype: str = get_pydantic_type(self.post_gres_datatype)[0]\n        return pydantic_datatype\n\n    def is_user_defined_type(self) -&gt; bool:\n        \"\"\"Check if the column is a user-defined type.\"\"\"\n        return self.post_gres_datatype == 'USER-DEFINED'\n\n    def nullable(self) -&gt; bool:\n        \"\"\"Check if the column is nullable.\"\"\"\n        return self.is_nullable if self.is_nullable is not None else False\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.ColumnInfo.has_default","title":"<code>has_default</code>  <code>property</code>","text":"<p>Check if the column has a default value.</p>"},{"location":"api/api-reference/#supabase_pydantic.db.models.ColumnInfo.is_generated","title":"<code>is_generated</code>  <code>property</code>","text":"<p>Check if the column is auto-generated (identity or serial).</p>"},{"location":"api/api-reference/#supabase_pydantic.db.models.ColumnInfo.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the column.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the column.\"\"\"\n    return f'ColumnInfo({self.name}, {self.post_gres_datatype})'\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.ColumnInfo.is_user_defined_type","title":"<code>is_user_defined_type()</code>","text":"<p>Check if the column is a user-defined type.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def is_user_defined_type(self) -&gt; bool:\n    \"\"\"Check if the column is a user-defined type.\"\"\"\n    return self.post_gres_datatype == 'USER-DEFINED'\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.ColumnInfo.nullable","title":"<code>nullable()</code>","text":"<p>Check if the column is nullable.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def nullable(self) -&gt; bool:\n    \"\"\"Check if the column is nullable.\"\"\"\n    return self.is_nullable if self.is_nullable is not None else False\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.ColumnInfo.orm_datatype","title":"<code>orm_datatype(orm_type=OrmType.PYDANTIC)</code>","text":"<p>Get the datatype for a column.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def orm_datatype(self, orm_type: OrmType = OrmType.PYDANTIC) -&gt; str:\n    \"\"\"Get the datatype for a column.\"\"\"\n    if orm_type == OrmType.SQLALCHEMY:\n        sql_datatype: str = get_sqlalchemy_type(self.post_gres_datatype)[0]\n        return sql_datatype\n\n    pydantic_datatype: str = get_pydantic_type(self.post_gres_datatype)[0]\n    return pydantic_datatype\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.ColumnInfo.orm_imports","title":"<code>orm_imports(orm_type=OrmType.PYDANTIC)</code>","text":"<p>Get the unique import statements for a column.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def orm_imports(self, orm_type: OrmType = OrmType.PYDANTIC) -&gt; set[str | None]:\n    \"\"\"Get the unique import statements for a column.\"\"\"\n    imports = set()  # future proofing in case multiple imports are needed\n    if orm_type == OrmType.SQLALCHEMY:\n        i = get_sqlalchemy_type(self.post_gres_datatype, ('Any', 'from sqlalchemy import Column'))[1]\n    else:\n        i = get_pydantic_type(self.post_gres_datatype)[1]\n    imports.add(i)\n    return imports\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.ConstraintInfo","title":"<code>ConstraintInfo</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AsDictParent</code></p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>@dataclass\nclass ConstraintInfo(AsDictParent):\n    constraint_name: str\n    raw_constraint_type: str\n    constraint_definition: str\n    columns: list[str] = field(default_factory=list)\n\n    def constraint_type(self) -&gt; str:\n        \"\"\"Get the constraint type.\"\"\"\n        constraint_type: str = CONSTRAINT_TYPE_MAP.get(self.raw_constraint_type.lower(), 'OTHER')\n        return constraint_type\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the constraint.\"\"\"\n        return f'ConstraintInfo({self.constraint_name}, {self.constraint_type()})'\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.ConstraintInfo.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the constraint.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the constraint.\"\"\"\n    return f'ConstraintInfo({self.constraint_name}, {self.constraint_type()})'\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.ConstraintInfo.constraint_type","title":"<code>constraint_type()</code>","text":"<p>Get the constraint type.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def constraint_type(self) -&gt; str:\n    \"\"\"Get the constraint type.\"\"\"\n    constraint_type: str = CONSTRAINT_TYPE_MAP.get(self.raw_constraint_type.lower(), 'OTHER')\n    return constraint_type\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.DatabaseConnectionParams","title":"<code>DatabaseConnectionParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base model for database connection parameters.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>class DatabaseConnectionParams(BaseModel):\n    \"\"\"Base model for database connection parameters.\"\"\"\n\n    conn_type: str = Field(..., description=\"Connection type identifier (e.g., 'postgresql', 'mysql')\")\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.DirectConnectionParams","title":"<code>DirectConnectionParams</code>","text":"<p>               Bases: <code>DatabaseConnectionParams</code></p> <p>Connection parameters for direct database connection.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>class DirectConnectionParams(DatabaseConnectionParams):\n    \"\"\"Connection parameters for direct database connection.\"\"\"\n\n    dbname: str = Field(..., description='Database name')\n    user: str = Field(..., description='Username for database connection')\n    password: str = Field(..., description='Password for database connection')\n    host: str = Field(..., description='Database host')\n    port: str = Field(..., description='Database port')\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.MySQLConnectionParams","title":"<code>MySQLConnectionParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>MySQL connection parameters.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>class MySQLConnectionParams(BaseModel):\n    \"\"\"MySQL connection parameters.\"\"\"\n\n    db_url: str | None = None\n    dbname: str | None = None\n    user: str | None = None\n    password: str | None = None\n    host: str | None = None\n    port: str | None = Field(default='3306', description='MySQL default port is 3306')\n\n    @field_validator('port')\n    def validate_port(cls, v: str | int | None) -&gt; str | None:\n        \"\"\"Validate that port is a valid integer.\"\"\"\n        if v is not None:\n            if isinstance(v, str):\n                try:\n                    return str(int(v))\n                except ValueError:\n                    raise ValueError('Port must be a valid number')\n            # Convert int to str to ensure consistent return type\n            elif isinstance(v, int):\n                return str(v)\n        return v\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert to dictionary, excluding None values.\"\"\"\n        # Handle both Pydantic v1 and v2 APIs\n        if hasattr(self, 'model_dump'):\n            # Pydantic v2\n            return {k: v for k, v in self.model_dump().items() if v is not None}\n        else:\n            # Pydantic v1\n            return {k: v for k, v in self.dict().items() if v is not None}\n\n    def is_valid(self) -&gt; bool:\n        \"\"\"Check if parameters are valid for connection.\"\"\"\n        if self.db_url is not None:\n            return True\n        return all([self.dbname, self.user, self.password, self.host, self.port])\n\n    model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.MySQLConnectionParams.is_valid","title":"<code>is_valid()</code>","text":"<p>Check if parameters are valid for connection.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def is_valid(self) -&gt; bool:\n    \"\"\"Check if parameters are valid for connection.\"\"\"\n    if self.db_url is not None:\n        return True\n    return all([self.dbname, self.user, self.password, self.host, self.port])\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.MySQLConnectionParams.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary, excluding None values.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert to dictionary, excluding None values.\"\"\"\n    # Handle both Pydantic v1 and v2 APIs\n    if hasattr(self, 'model_dump'):\n        # Pydantic v2\n        return {k: v for k, v in self.model_dump().items() if v is not None}\n    else:\n        # Pydantic v1\n        return {k: v for k, v in self.dict().items() if v is not None}\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.MySQLConnectionParams.validate_port","title":"<code>validate_port(v)</code>","text":"<p>Validate that port is a valid integer.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>@field_validator('port')\ndef validate_port(cls, v: str | int | None) -&gt; str | None:\n    \"\"\"Validate that port is a valid integer.\"\"\"\n    if v is not None:\n        if isinstance(v, str):\n            try:\n                return str(int(v))\n            except ValueError:\n                raise ValueError('Port must be a valid number')\n        # Convert int to str to ensure consistent return type\n        elif isinstance(v, int):\n            return str(v)\n    return v\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.PostgresConnectionParams","title":"<code>PostgresConnectionParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Connection parameters for PostgreSQL database.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>class PostgresConnectionParams(BaseModel):\n    \"\"\"Connection parameters for PostgreSQL database.\"\"\"\n\n    # Either db_url or direct connection params must be provided\n    dbname: str | None = Field(None, description='Database name')\n    user: str | None = Field(None, description='Username for database connection')\n    password: str | None = Field(None, description='Password for database connection')\n    host: str | None = Field(None, description='Database host')\n    port: str | None = Field(None, description='Database port')\n    db_url: str | None = Field(\n        None, description='Database connection URL in format: postgresql://username:password@host:port/database'\n    )\n\n    @field_validator('db_url')\n    def validate_db_url(cls, v: str | None) -&gt; str | None:\n        \"\"\"Validate db_url format.\"\"\"\n        if v is not None:\n            # Basic validation that it starts with postgresql://\n            if not v.startswith('postgresql://'):\n                raise ValueError(\"PostgreSQL connection URL must start with 'postgresql://'\")\n        return v\n\n    @field_validator('port')\n    def validate_port(cls, v: str | int | None) -&gt; str | None:\n        \"\"\"Validate port is numeric.\"\"\"\n        if v is not None:\n            # Convert to int if it's a string\n            if isinstance(v, str):\n                try:\n                    return str(int(v))\n                except ValueError:\n                    raise ValueError('Port must be a valid number')\n            # Convert int to str to ensure consistent return type\n            elif isinstance(v, int):\n                return str(v)\n        return v\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert to dictionary, excluding None values.\"\"\"\n        # Handle both Pydantic v1 and v2 APIs\n        if hasattr(self, 'model_dump'):\n            # Pydantic v2\n            return {k: v for k, v in self.model_dump().items() if v is not None}\n        else:\n            # Pydantic v1\n            return {k: v for k, v in self.dict().items() if v is not None}\n\n    def is_valid(self) -&gt; bool:\n        \"\"\"Check if parameters are valid for connection.\"\"\"\n        if self.db_url is not None:\n            return True\n        required_direct_params = [self.dbname, self.user, self.password, self.host, self.port]\n        return all(param is not None for param in required_direct_params)\n\n    model_config = ConfigDict(extra='forbid')\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.PostgresConnectionParams.is_valid","title":"<code>is_valid()</code>","text":"<p>Check if parameters are valid for connection.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def is_valid(self) -&gt; bool:\n    \"\"\"Check if parameters are valid for connection.\"\"\"\n    if self.db_url is not None:\n        return True\n    required_direct_params = [self.dbname, self.user, self.password, self.host, self.port]\n    return all(param is not None for param in required_direct_params)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.PostgresConnectionParams.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary, excluding None values.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert to dictionary, excluding None values.\"\"\"\n    # Handle both Pydantic v1 and v2 APIs\n    if hasattr(self, 'model_dump'):\n        # Pydantic v2\n        return {k: v for k, v in self.model_dump().items() if v is not None}\n    else:\n        # Pydantic v1\n        return {k: v for k, v in self.dict().items() if v is not None}\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.PostgresConnectionParams.validate_db_url","title":"<code>validate_db_url(v)</code>","text":"<p>Validate db_url format.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>@field_validator('db_url')\ndef validate_db_url(cls, v: str | None) -&gt; str | None:\n    \"\"\"Validate db_url format.\"\"\"\n    if v is not None:\n        # Basic validation that it starts with postgresql://\n        if not v.startswith('postgresql://'):\n            raise ValueError(\"PostgreSQL connection URL must start with 'postgresql://'\")\n    return v\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.PostgresConnectionParams.validate_port","title":"<code>validate_port(v)</code>","text":"<p>Validate port is numeric.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>@field_validator('port')\ndef validate_port(cls, v: str | int | None) -&gt; str | None:\n    \"\"\"Validate port is numeric.\"\"\"\n    if v is not None:\n        # Convert to int if it's a string\n        if isinstance(v, str):\n            try:\n                return str(int(v))\n            except ValueError:\n                raise ValueError('Port must be a valid number')\n        # Convert int to str to ensure consistent return type\n        elif isinstance(v, int):\n            return str(v)\n    return v\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo","title":"<code>TableInfo</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AsDictParent</code></p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>@dataclass\nclass TableInfo(AsDictParent):\n    name: str\n    schema: str = 'public'\n    table_type: Literal['BASE TABLE', 'VIEW'] = 'BASE TABLE'\n    is_bridge: bool = False  # whether the table is a bridge table\n    columns: list[ColumnInfo] = field(default_factory=list)\n    foreign_keys: list[ForeignKeyInfo] = field(default_factory=list)\n    constraints: list[ConstraintInfo] = field(default_factory=list)\n    relationships: list[RelationshipInfo] = field(default_factory=list)\n    generated_data: list[dict] = field(default_factory=list)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the table.\"\"\"\n        return f'TableInfo({self.schema}.{self.name})'\n\n    def add_column(self, column: ColumnInfo) -&gt; None:\n        \"\"\"Add a column to the table.\"\"\"\n        self.columns.append(column)\n\n    def add_foreign_key(self, fk: ForeignKeyInfo) -&gt; None:\n        \"\"\"Add a foreign key to the table.\"\"\"\n        self.foreign_keys.append(fk)\n\n    def add_constraint(self, constraint: ConstraintInfo) -&gt; None:\n        \"\"\"Add a constraint to the table.\"\"\"\n        self.constraints.append(constraint)\n\n    def aliasing_in_columns(self) -&gt; bool:\n        \"\"\"Check if any column within a table has an alias.\"\"\"\n        return any(bool(c.alias is not None) for c in self.columns)\n\n    def table_dependencies(self) -&gt; set[str]:\n        \"\"\"Get the table dependencies (foreign tables) for a table.\"\"\"\n        return set([fk.foreign_table_name for fk in self.foreign_keys])\n\n    def primary_key(self) -&gt; list[str]:\n        \"\"\"Get the primary key for a table.\"\"\"\n        if self.table_type == 'BASE TABLE':\n            for constraint in self.constraints:\n                if constraint.constraint_type() == 'PRIMARY KEY':\n                    return constraint.columns\n        return []  # Return an empty list if no primary key is found\n\n    def primary_is_composite(self) -&gt; bool:\n        \"\"\"Check if the primary key is composite.\"\"\"\n        return len(self.primary_key()) &gt; 1\n\n    def get_primary_columns(self, sort_results: bool = False) -&gt; list[ColumnInfo]:\n        \"\"\"Get the primary columns for a table.\"\"\"\n        return self._get_columns(is_primary=True, sort_results=sort_results)\n\n    def get_secondary_columns(self, sort_results: bool = False) -&gt; list[ColumnInfo]:\n        \"\"\"Get the secondary columns for a table.\"\"\"\n        return self._get_columns(is_primary=False, sort_results=sort_results)\n\n    def _get_columns(self, is_primary: bool = True, sort_results: bool = False) -&gt; list[ColumnInfo]:\n        \"\"\"Private function to get the primary or secondary columns for a table.\"\"\"\n        if is_primary:\n            res = [c for c in self.columns if c.name in self.primary_key()]\n        else:\n            res = [c for c in self.columns if c.name not in self.primary_key()]\n\n        if sort_results:\n            res.sort(key=lambda x: x.name)\n\n        return res\n\n    def sort_and_separate_columns(\n        self, separate_nullable: bool = False, separate_primary_key: bool = False\n    ) -&gt; SortedColumns:\n        \"\"\"Sort and combine columns based on is_nullable attribute.\n\n        Args:\n            separate_nullable: Whether to separate nullable and non-nullable columns.\n            separate_primary_key: Whether to separate primary key and secondary columns.\n\n        Returns:\n            A dictionary with keys, nullable, non_nullable, and remaining as keys\n            and lists of ColumnInfo objects as values.\n        \"\"\"\n        # result: dict[str, list[ColumnInfo]] = {'keys': [], 'nullable': [], 'non_nullable': [], 'remaining': []}\n        result: SortedColumns = SortedColumns([], [], [], [])\n        if separate_primary_key:\n            result.primary_keys = self.get_primary_columns(sort_results=True)\n            result.remaining = self.get_secondary_columns(sort_results=True)\n        else:\n            result.remaining = sorted(self.columns, key=lambda x: x.name)\n\n        if separate_nullable:\n            nullable_columns = [column for column in result.remaining if column.is_nullable]  # already sorted\n            non_nullable_columns = [column for column in result.remaining if not column.is_nullable]\n\n            # Combine them with non-nullable first\n            result.nullable = nullable_columns\n            result.non_nullable = non_nullable_columns\n            result.remaining = []\n\n        return result\n\n    def has_unique_constraint(self) -&gt; bool:\n        \"\"\"Check if the table has unique constraints.\"\"\"\n        return any(c.constraint_type() == 'UNIQUE' for c in self.constraints)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the table.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the table.\"\"\"\n    return f'TableInfo({self.schema}.{self.name})'\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.add_column","title":"<code>add_column(column)</code>","text":"<p>Add a column to the table.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def add_column(self, column: ColumnInfo) -&gt; None:\n    \"\"\"Add a column to the table.\"\"\"\n    self.columns.append(column)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.add_constraint","title":"<code>add_constraint(constraint)</code>","text":"<p>Add a constraint to the table.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def add_constraint(self, constraint: ConstraintInfo) -&gt; None:\n    \"\"\"Add a constraint to the table.\"\"\"\n    self.constraints.append(constraint)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.add_foreign_key","title":"<code>add_foreign_key(fk)</code>","text":"<p>Add a foreign key to the table.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def add_foreign_key(self, fk: ForeignKeyInfo) -&gt; None:\n    \"\"\"Add a foreign key to the table.\"\"\"\n    self.foreign_keys.append(fk)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.aliasing_in_columns","title":"<code>aliasing_in_columns()</code>","text":"<p>Check if any column within a table has an alias.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def aliasing_in_columns(self) -&gt; bool:\n    \"\"\"Check if any column within a table has an alias.\"\"\"\n    return any(bool(c.alias is not None) for c in self.columns)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.get_primary_columns","title":"<code>get_primary_columns(sort_results=False)</code>","text":"<p>Get the primary columns for a table.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def get_primary_columns(self, sort_results: bool = False) -&gt; list[ColumnInfo]:\n    \"\"\"Get the primary columns for a table.\"\"\"\n    return self._get_columns(is_primary=True, sort_results=sort_results)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.get_secondary_columns","title":"<code>get_secondary_columns(sort_results=False)</code>","text":"<p>Get the secondary columns for a table.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def get_secondary_columns(self, sort_results: bool = False) -&gt; list[ColumnInfo]:\n    \"\"\"Get the secondary columns for a table.\"\"\"\n    return self._get_columns(is_primary=False, sort_results=sort_results)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.has_unique_constraint","title":"<code>has_unique_constraint()</code>","text":"<p>Check if the table has unique constraints.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def has_unique_constraint(self) -&gt; bool:\n    \"\"\"Check if the table has unique constraints.\"\"\"\n    return any(c.constraint_type() == 'UNIQUE' for c in self.constraints)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.primary_is_composite","title":"<code>primary_is_composite()</code>","text":"<p>Check if the primary key is composite.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def primary_is_composite(self) -&gt; bool:\n    \"\"\"Check if the primary key is composite.\"\"\"\n    return len(self.primary_key()) &gt; 1\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.primary_key","title":"<code>primary_key()</code>","text":"<p>Get the primary key for a table.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def primary_key(self) -&gt; list[str]:\n    \"\"\"Get the primary key for a table.\"\"\"\n    if self.table_type == 'BASE TABLE':\n        for constraint in self.constraints:\n            if constraint.constraint_type() == 'PRIMARY KEY':\n                return constraint.columns\n    return []  # Return an empty list if no primary key is found\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.sort_and_separate_columns","title":"<code>sort_and_separate_columns(separate_nullable=False, separate_primary_key=False)</code>","text":"<p>Sort and combine columns based on is_nullable attribute.</p> <p>Parameters:</p> Name Type Description Default <code>separate_nullable</code> <code>bool</code> <p>Whether to separate nullable and non-nullable columns.</p> <code>False</code> <code>separate_primary_key</code> <code>bool</code> <p>Whether to separate primary key and secondary columns.</p> <code>False</code> <p>Returns:</p> Type Description <code>SortedColumns</code> <p>A dictionary with keys, nullable, non_nullable, and remaining as keys</p> <code>SortedColumns</code> <p>and lists of ColumnInfo objects as values.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def sort_and_separate_columns(\n    self, separate_nullable: bool = False, separate_primary_key: bool = False\n) -&gt; SortedColumns:\n    \"\"\"Sort and combine columns based on is_nullable attribute.\n\n    Args:\n        separate_nullable: Whether to separate nullable and non-nullable columns.\n        separate_primary_key: Whether to separate primary key and secondary columns.\n\n    Returns:\n        A dictionary with keys, nullable, non_nullable, and remaining as keys\n        and lists of ColumnInfo objects as values.\n    \"\"\"\n    # result: dict[str, list[ColumnInfo]] = {'keys': [], 'nullable': [], 'non_nullable': [], 'remaining': []}\n    result: SortedColumns = SortedColumns([], [], [], [])\n    if separate_primary_key:\n        result.primary_keys = self.get_primary_columns(sort_results=True)\n        result.remaining = self.get_secondary_columns(sort_results=True)\n    else:\n        result.remaining = sorted(self.columns, key=lambda x: x.name)\n\n    if separate_nullable:\n        nullable_columns = [column for column in result.remaining if column.is_nullable]  # already sorted\n        non_nullable_columns = [column for column in result.remaining if not column.is_nullable]\n\n        # Combine them with non-nullable first\n        result.nullable = nullable_columns\n        result.non_nullable = non_nullable_columns\n        result.remaining = []\n\n    return result\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.TableInfo.table_dependencies","title":"<code>table_dependencies()</code>","text":"<p>Get the table dependencies (foreign tables) for a table.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def table_dependencies(self) -&gt; set[str]:\n    \"\"\"Get the table dependencies (foreign tables) for a table.\"\"\"\n    return set([fk.foreign_table_name for fk in self.foreign_keys])\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.URLConnectionParams","title":"<code>URLConnectionParams</code>","text":"<p>               Bases: <code>DatabaseConnectionParams</code></p> <p>Connection parameters for URL-based database connection.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>class URLConnectionParams(DatabaseConnectionParams):\n    \"\"\"Connection parameters for URL-based database connection.\"\"\"\n\n    db_url: str = Field(\n        ..., description='Database connection URL in format: dialect://username:password@host:port/database'\n    )\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.UserEnumType","title":"<code>UserEnumType</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AsDictParent</code></p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>@dataclass\nclass UserEnumType(AsDictParent):\n    type_name: str\n    namespace: str\n    owner: str\n    category: str\n    is_defined: bool\n    type: str\n    enum_values: list[str] = field(default_factory=list)\n\n    def matches_type_name(self, type_name: str) -&gt; bool:\n        \"\"\"Check if a given type name matches this enum type, handling PostgreSQL array naming conventions.\"\"\"\n        if not type_name:\n            return False\n\n        # Remove all leading underscores (PostgreSQL array types add underscores)\n        clean_name = type_name\n        while clean_name.startswith('_'):\n            clean_name = clean_name[1:]\n\n        # Remove array brackets if present\n        if clean_name.endswith('[]'):\n            clean_name = clean_name[:-2]\n\n        # Remove quotes if present\n        if clean_name.startswith('\"') and clean_name.endswith('\"'):\n            clean_name = clean_name[1:-1]\n\n        # Handle schema qualification (e.g., public.Fifth_Type)\n        if '.' in clean_name:\n            clean_name = clean_name.split('.')[-1]\n\n        # PostgreSQL sometimes lowercases type names for arrays\n        # Compare both lowercased and original\n        return self.type_name.lower() == clean_name.lower()\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.db.models.UserEnumType.matches_type_name","title":"<code>matches_type_name(type_name)</code>","text":"<p>Check if a given type name matches this enum type, handling PostgreSQL array naming conventions.</p> Source code in <code>src/supabase_pydantic/db/models.py</code> <pre><code>def matches_type_name(self, type_name: str) -&gt; bool:\n    \"\"\"Check if a given type name matches this enum type, handling PostgreSQL array naming conventions.\"\"\"\n    if not type_name:\n        return False\n\n    # Remove all leading underscores (PostgreSQL array types add underscores)\n    clean_name = type_name\n    while clean_name.startswith('_'):\n        clean_name = clean_name[1:]\n\n    # Remove array brackets if present\n    if clean_name.endswith('[]'):\n        clean_name = clean_name[:-2]\n\n    # Remove quotes if present\n    if clean_name.startswith('\"') and clean_name.endswith('\"'):\n        clean_name = clean_name[1:-1]\n\n    # Handle schema qualification (e.g., public.Fifth_Type)\n    if '.' in clean_name:\n        clean_name = clean_name.split('.')[-1]\n\n    # PostgreSQL sometimes lowercases type names for arrays\n    # Compare both lowercased and original\n    return self.type_name.lower() == clean_name.lower()\n</code></pre>"},{"location":"api/api-reference/#core-models","title":"Core Models","text":""},{"location":"api/api-reference/#supabase_pydantic.core.models.EnumInfo","title":"<code>EnumInfo</code>  <code>dataclass</code>","text":"Source code in <code>src/supabase_pydantic/core/models.py</code> <pre><code>@dataclass\nclass EnumInfo:\n    name: str  # The name of the enum type in the DB\n    values: list[str]  # The possible values for the enum\n    schema: str = 'public'  # The schema, defaulting to 'public'\n\n    def python_class_name(self) -&gt; str:\n        \"\"\"Converts DB enum name to PascalCase for Python class, prefixed by schema.\n\n        Handles various input formats:\n        - snake_case: 'order_status' -&gt; 'OrderStatusEnum'\n        - camelCase: 'thirdType' -&gt; 'ThirdTypeEnum'\n        - PascalCase: 'FourthType' -&gt; 'FourthTypeEnum'\n        - mixed: 'Fifth_Type' -&gt; 'FifthTypeEnum'\n        - with leading underscore: '_first_type' -&gt; 'FirstTypeEnum'\n\n        Final class name is prefixed by schema: 'public.order_status' -&gt; 'PublicOrderStatusEnum'\n        \"\"\"\n        # Handle empty name edge case\n        if not self.name:\n            return f'{self.schema.capitalize()}Enum'\n\n        # Remove leading underscore if present (for PostgreSQL compatibility)\n        clean_name = self.name\n        if clean_name.startswith('_'):\n            clean_name = clean_name[1:]\n\n        # Special case: if the name is already PascalCase or camelCase without underscores\n        if '_' not in clean_name and any(c.isupper() for c in clean_name):\n            # Ensure first character is uppercase\n            class_name = clean_name[0].upper() + clean_name[1:] + 'Enum'\n        else:\n            # Standard snake_case processing\n            class_name = ''.join(word.capitalize() for word in clean_name.split('_')) + 'Enum'\n\n        # Add schema prefix\n        return f'{self.schema.capitalize()}{class_name}'\n\n    def python_member_name(self, value: str) -&gt; str:\n        \"\"\"Converts enum value to a valid Python identifier.\n\n        e.g., 'pending_new' -&gt; 'pending_new'\n        \"\"\"\n        return value.lower()\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.core.models.EnumInfo.python_class_name","title":"<code>python_class_name()</code>","text":"<p>Converts DB enum name to PascalCase for Python class, prefixed by schema.</p> <p>Handles various input formats: - snake_case: 'order_status' -&gt; 'OrderStatusEnum' - camelCase: 'thirdType' -&gt; 'ThirdTypeEnum' - PascalCase: 'FourthType' -&gt; 'FourthTypeEnum' - mixed: 'Fifth_Type' -&gt; 'FifthTypeEnum' - with leading underscore: '_first_type' -&gt; 'FirstTypeEnum'</p> <p>Final class name is prefixed by schema: 'public.order_status' -&gt; 'PublicOrderStatusEnum'</p> Source code in <code>src/supabase_pydantic/core/models.py</code> <pre><code>def python_class_name(self) -&gt; str:\n    \"\"\"Converts DB enum name to PascalCase for Python class, prefixed by schema.\n\n    Handles various input formats:\n    - snake_case: 'order_status' -&gt; 'OrderStatusEnum'\n    - camelCase: 'thirdType' -&gt; 'ThirdTypeEnum'\n    - PascalCase: 'FourthType' -&gt; 'FourthTypeEnum'\n    - mixed: 'Fifth_Type' -&gt; 'FifthTypeEnum'\n    - with leading underscore: '_first_type' -&gt; 'FirstTypeEnum'\n\n    Final class name is prefixed by schema: 'public.order_status' -&gt; 'PublicOrderStatusEnum'\n    \"\"\"\n    # Handle empty name edge case\n    if not self.name:\n        return f'{self.schema.capitalize()}Enum'\n\n    # Remove leading underscore if present (for PostgreSQL compatibility)\n    clean_name = self.name\n    if clean_name.startswith('_'):\n        clean_name = clean_name[1:]\n\n    # Special case: if the name is already PascalCase or camelCase without underscores\n    if '_' not in clean_name and any(c.isupper() for c in clean_name):\n        # Ensure first character is uppercase\n        class_name = clean_name[0].upper() + clean_name[1:] + 'Enum'\n    else:\n        # Standard snake_case processing\n        class_name = ''.join(word.capitalize() for word in clean_name.split('_')) + 'Enum'\n\n    # Add schema prefix\n    return f'{self.schema.capitalize()}{class_name}'\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.core.models.EnumInfo.python_member_name","title":"<code>python_member_name(value)</code>","text":"<p>Converts enum value to a valid Python identifier.</p> <p>e.g., 'pending_new' -&gt; 'pending_new'</p> Source code in <code>src/supabase_pydantic/core/models.py</code> <pre><code>def python_member_name(self, value: str) -&gt; str:\n    \"\"\"Converts enum value to a valid Python identifier.\n\n    e.g., 'pending_new' -&gt; 'pending_new'\n    \"\"\"\n    return value.lower()\n</code></pre>"},{"location":"api/api-reference/#writers","title":"Writers","text":""},{"location":"api/api-reference/#serialization","title":"Serialization","text":""},{"location":"api/api-reference/#supabase_pydantic.utils.serialization.AsDictParent","title":"<code>AsDictParent</code>  <code>dataclass</code>","text":"Source code in <code>src/supabase_pydantic/utils/serialization.py</code> <pre><code>@dataclass\nclass AsDictParent:\n    def as_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert the dataclass instance to a dictionary.\"\"\"\n        return asdict(self)\n\n    def __str__(self) -&gt; str:\n        return json.dumps(asdict(self), indent=4)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.utils.serialization.AsDictParent.as_dict","title":"<code>as_dict()</code>","text":"<p>Convert the dataclass instance to a dictionary.</p> Source code in <code>src/supabase_pydantic/utils/serialization.py</code> <pre><code>def as_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the dataclass instance to a dictionary.\"\"\"\n    return asdict(self)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.utils.serialization.CustomJsonEncoder","title":"<code>CustomJsonEncoder</code>","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>Custom JSON encoder for encoding decimal and datetime.</p> Source code in <code>src/supabase_pydantic/utils/serialization.py</code> <pre><code>class CustomJsonEncoder(json.JSONEncoder):\n    \"\"\"Custom JSON encoder for encoding decimal and datetime.\"\"\"\n\n    def default(self, o: object) -&gt; Any:\n        \"\"\"Encode decimal and datetime objects.\"\"\"\n        if isinstance(o, decimal.Decimal):\n            return str(o)\n        elif isinstance(o, datetime | date):\n            return o.isoformat()\n        return super().default(o)\n</code></pre>"},{"location":"api/api-reference/#supabase_pydantic.utils.serialization.CustomJsonEncoder.default","title":"<code>default(o)</code>","text":"<p>Encode decimal and datetime objects.</p> Source code in <code>src/supabase_pydantic/utils/serialization.py</code> <pre><code>def default(self, o: object) -&gt; Any:\n    \"\"\"Encode decimal and datetime objects.\"\"\"\n    if isinstance(o, decimal.Decimal):\n        return str(o)\n    elif isinstance(o, datetime | date):\n        return o.isoformat()\n    return super().default(o)\n</code></pre>"},{"location":"api/cli/","title":"CLI Reference","text":""},{"location":"examples/add-seed-sql-data/","title":"Create Test Data for your SQL Database","text":"<p>This example demonstrates how to create test data for your SQL database using the <code>--seed</code> option when generating Pydantic models with <code>supabase-pydantic</code>, a very useful feature when you need to populate your database with test data.</p> <p>Please note ...</p> <p>This is a developing feature . It is imperfect, so please report any issues you encounter.</p>"},{"location":"examples/add-seed-sql-data/#prerequisites","title":"Prerequisites","text":"<p>You should follow the setup &amp; prerequisites guide in the Slack Clone example to initialize your local Supabase instance.</p>"},{"location":"examples/add-seed-sql-data/#generating-seed-data","title":"Generating Seed Data","text":"<p>To generate seed data, you simply need to append the <code>--seed</code> option to the <code>generate</code> command. For example, run the following command:</p> Generate Seed Data<pre><code>$ sb-pydantic gen --type pydantic --framework fastapi --local --seed\n\n2023-07-15 10:25:18 - INFO - PostGres connection is open.\n2023-07-15 10:25:19 - INFO - PostGres connection is closed.\n2023-07-15 10:25:19 - INFO - Generating FastAPI Pydantic models...\n2023-07-15 10:25:22 - INFO - FastAPI Pydantic models generated successfully: /path/to/your/project/entities/fastapi/schemas_latest.py\n2023-07-15 10:25:22 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schemas_latest.py\n2023-07-15 10:25:22 - INFO - Generating seed data...\n2023-07-15 10:25:24 - INFO - Seed data generated successfully: /path/to/your/project/entities/seed_latest.sql\n</code></pre> <p>Note that the seed sql file will be generated in the <code>entities</code> directory of your project: </p> seed_latest.sql<pre><code>-- role_permissions\nINSERT INTO role_permissions (id, role, permission) VALUES (87803, 'admin', 'channels.delete');\nINSERT INTO role_permissions (id, role, permission) VALUES (31084, 'admin', 'messages.delete');\nINSERT INTO role_permissions (id, role, permission) VALUES (33762, 'moderator', 'channels.delete');\nINSERT INTO role_permissions (id, role, permission) VALUES (48955, 'moderator', 'messages.delete');\n\n-- users\nINSERT INTO users (id, username, status) VALUES ('525116b8-901b-4828-be03-c44bb3de3b3b', 'hdavis', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('a2fbe746-3bce-4e28-bce6-305775398857', 'carolyn24', NULL);\nINSERT INTO users (id, username, status) VALUES ('28959251-33ed-4bb4-8da7-6903704348f3', 'wthompson', 'OFFLINE');\nINSERT INTO users (id, username, status) VALUES ('deeae4e6-1fc3-40ed-9966-30bebaddeb5a', 'kim76', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('33c6593e-8697-4a67-b729-455cbc0d498b', 'rwise', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('90a76966-ecb9-4114-af3b-f23471ba5616', 'daniel17', NULL);\nINSERT INTO users (id, username, status) VALUES ('1471c3bc-dc10-4d91-9918-271e6ffcf32a', 'mcdowelljohn', NULL);\nINSERT INTO users (id, username, status) VALUES ('30d3098d-a436-443b-a4fc-2529e74a0fa9', 'debra45', 'OFFLINE');\nINSERT INTO users (id, username, status) VALUES ('00f2e429-83dc-4052-8643-e0c4d931bab2', 'phopkins', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('22b3bfaf-f35c-4e40-90cf-87805c4a3c2d', 'brittanyhart', 'OFFLINE');\nINSERT INTO users (id, username, status) VALUES ('8da77568-8b83-4d70-b872-a4d5472fa0c0', 'kayla82', 'OFFLINE');\nINSERT INTO users (id, username, status) VALUES ('6a731db3-a36d-4d47-983c-04c97b91630b', 'lle', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('55020e0b-5c4e-40f9-942c-0b44529043a6', 'justinmills', 'OFFLINE');\nINSERT INTO users (id, username, status) VALUES ('3ac52e44-f864-423d-81fa-4c092d06369c', 'dallen', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('379b0a29-14af-4779-90ed-6c97e9d9d92d', 'jenniferhughes', 'OFFLINE');\nINSERT INTO users (id, username, status) VALUES ('194ab5d9-1fd0-4ba2-83c9-eb920a47f84b', 'jenniferstewart', 'OFFLINE');\nINSERT INTO users (id, username, status) VALUES ('448a00d4-b5ae-4d52-9a17-6bc0407ddae4', 'christopher98', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('56a00eec-628a-465d-a5c0-5a9562cdbbf8', 'mark68', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('44ddfeaf-bee9-48b7-a554-ef09082f4088', 'gibsongary', NULL);\nINSERT INTO users (id, username, status) VALUES ('ef61ef82-53f4-41ea-94e7-ad67f6379b91', 'nortoncrystal', NULL);\nINSERT INTO users (id, username, status) VALUES ('6d074ed9-cfa9-4bbc-9be8-14ad71bb1330', 'pmccarthy', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('fd26ba43-dbba-4c33-9b7d-262f91e8b7a0', 'benjamin81', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('616d31dc-139f-44a6-b200-3a4ffd79834f', 'daniel42', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('4f0085e7-155b-4d46-9451-28e5e62ceb7e', 'jaredgay', NULL);\nINSERT INTO users (id, username, status) VALUES ('222dc7aa-7f87-408c-b8e4-9c237d44fb5b', 'vturner', 'OFFLINE');\nINSERT INTO users (id, username, status) VALUES ('b1bba5eb-2e94-4bac-9e8e-251b13c13ad3', NULL, 'OFFLINE');\nINSERT INTO users (id, username, status) VALUES ('50e2395d-31c4-4b13-ac82-1963b7ec3e8a', 'crystal35', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('00891d6f-be15-40ea-96b5-b8035d6164e7', 'jennifer17', NULL);\nINSERT INTO users (id, username, status) VALUES ('97fdb7cc-4cbb-42ab-b0ad-4dabd22aca31', 'thomasmunoz', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('ec1c09f2-9b79-48f9-b838-df6db4ec88f0', NULL, 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('146a1828-e631-49f6-98f1-42d222b7931f', 'montgomeryjessica', 'OFFLINE');\nINSERT INTO users (id, username, status) VALUES ('efe27982-b5c2-46fc-b287-8c61729e8a1c', 'jamesduran', 'OFFLINE');\nINSERT INTO users (id, username, status) VALUES ('b9d94cba-bde5-41bc-a634-720d65c23cfb', 'earl09', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('291ecf4e-53e6-4227-80e3-7904e0f23368', 'valencialawrence', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('bfde79a0-19e4-42a6-93f0-aa33b5d0b16f', 'jason76', 'ONLINE');\nINSERT INTO users (id, username, status) VALUES ('7836b471-3efd-4ccd-a61d-9de717a0051f', NULL, 'OFFLINE');\n\n-- user_roles\nINSERT INTO user_roles (id, user_id, role) VALUES (83319, '33c6593e-8697-4a67-b729-455cbc0d498b', 'moderator');\nINSERT INTO user_roles (id, user_id, role) VALUES (33898, '90a76966-ecb9-4114-af3b-f23471ba5616', 'moderator');\nINSERT INTO user_roles (id, user_id, role) VALUES (85861, 'a2fbe746-3bce-4e28-bce6-305775398857', 'admin');\nINSERT INTO user_roles (id, user_id, role) VALUES (10985, 'ef61ef82-53f4-41ea-94e7-ad67f6379b91', 'admin');\nINSERT INTO user_roles (id, user_id, role) VALUES (82816, 'b1bba5eb-2e94-4bac-9e8e-251b13c13ad3', 'moderator');\nINSERT INTO user_roles (id, user_id, role) VALUES (74426, 'b9d94cba-bde5-41bc-a634-720d65c23cfb', 'moderator');\nINSERT INTO user_roles (id, user_id, role) VALUES (75966, 'ec1c09f2-9b79-48f9-b838-df6db4ec88f0', 'moderator');\nINSERT INTO user_roles (id, user_id, role) VALUES (84609, 'fd26ba43-dbba-4c33-9b7d-262f91e8b7a0', 'moderator');\nINSERT INTO user_roles (id, user_id, role) VALUES (50910, '4f0085e7-155b-4d46-9451-28e5e62ceb7e', 'admin');\nINSERT INTO user_roles (id, user_id, role) VALUES (37486, 'efe27982-b5c2-46fc-b287-8c61729e8a1c', 'admin');\nINSERT INTO user_roles (id, user_id, role) VALUES (47221, '6a731db3-a36d-4d47-983c-04c97b91630b', 'moderator');\nINSERT INTO user_roles (id, user_id, role) VALUES (78989, '22b3bfaf-f35c-4e40-90cf-87805c4a3c2d', 'admin');\nINSERT INTO user_roles (id, user_id, role) VALUES (95616, '4f0085e7-155b-4d46-9451-28e5e62ceb7e', 'moderator');\nINSERT INTO user_roles (id, user_id, role) VALUES (26133, '146a1828-e631-49f6-98f1-42d222b7931f', 'admin');\nINSERT INTO user_roles (id, user_id, role) VALUES (74435, '55020e0b-5c4e-40f9-942c-0b44529043a6', 'admin');\nINSERT INTO user_roles (id, user_id, role) VALUES (43973, 'efe27982-b5c2-46fc-b287-8c61729e8a1c', 'moderator');\nINSERT INTO user_roles (id, user_id, role) VALUES (20909, '33c6593e-8697-4a67-b729-455cbc0d498b', 'admin');\n\n-- channels\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (73167, '2020-05-19 19:56:22.739152', 'congress-glass-or', 'efe27982-b5c2-46fc-b287-8c61729e8a1c');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (59035, '2020-07-21 12:59:46.688203', 'strong-yes-garden', '30d3098d-a436-443b-a4fc-2529e74a0fa9');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (57011, '2024-03-05 13:59:28.859460', 'tax-yes-try', '3ac52e44-f864-423d-81fa-4c092d06369c');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (56051, '2022-01-17 12:16:38.051458', 'hit-discover', 'a2fbe746-3bce-4e28-bce6-305775398857');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (24499, '2022-07-22 05:04:16.900182', 'return-arrive-rock', '22b3bfaf-f35c-4e40-90cf-87805c4a3c2d');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (62758, '2021-12-10 05:16:23.680029', 'which-apply-voice', '7836b471-3efd-4ccd-a61d-9de717a0051f');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (82233, '2023-11-09 00:27:22.705116', 'thought-put-reduce', 'efe27982-b5c2-46fc-b287-8c61729e8a1c');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (76493, '2022-05-24 13:11:22.534508', 'cost-young-upon', '4f0085e7-155b-4d46-9451-28e5e62ceb7e');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (93212, '2023-07-09 12:11:52.868773', 'shake-experience', '6d074ed9-cfa9-4bbc-9be8-14ad71bb1330');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (64604, '2020-05-18 14:38:50.692194', 'pick-sure-hard-room', '6a731db3-a36d-4d47-983c-04c97b91630b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (38704, '2019-12-15 04:05:28.598066', 'college-enough-cup', 'b1bba5eb-2e94-4bac-9e8e-251b13c13ad3');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (91106, '2021-07-27 09:20:08.928559', 'total-example-call', '33c6593e-8697-4a67-b729-455cbc0d498b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (7055, '2023-09-30 02:58:06.518260', 'however-scientist', 'bfde79a0-19e4-42a6-93f0-aa33b5d0b16f');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (61443, '2024-03-13 13:13:17.621869', 'doctor-avoid-cell', '146a1828-e631-49f6-98f1-42d222b7931f');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (26048, '2022-07-31 14:10:03.903888', 'play-physical-glass', '50e2395d-31c4-4b13-ac82-1963b7ec3e8a');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (37632, '2020-01-11 22:53:32.668729', 'film-why-foot-five', 'deeae4e6-1fc3-40ed-9966-30bebaddeb5a');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (79473, '2022-09-08 23:58:29.804262', 'series-attack-no', 'efe27982-b5c2-46fc-b287-8c61729e8a1c');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (95748, '2019-08-28 23:07:41.358693', 'particularly', '33c6593e-8697-4a67-b729-455cbc0d498b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (32984, '2020-05-02 03:44:17.576074', 'social-rock-admit', '30d3098d-a436-443b-a4fc-2529e74a0fa9');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (44763, '2022-03-02 10:58:30.600494', 'majority-point-best', 'ef61ef82-53f4-41ea-94e7-ad67f6379b91');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (87801, '2019-12-06 10:13:13.380238', 'shake-fall-go', 'fd26ba43-dbba-4c33-9b7d-262f91e8b7a0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (26463, '2019-12-31 04:55:28.614491', 'fact-son-think', '3ac52e44-f864-423d-81fa-4c092d06369c');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (51366, '2020-07-22 22:34:00.752688', 'practice-capital', '30d3098d-a436-443b-a4fc-2529e74a0fa9');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (88239, '2023-01-29 16:35:12.975673', 'perhaps-education', '50e2395d-31c4-4b13-ac82-1963b7ec3e8a');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (93630, '2023-12-04 10:53:05.602732', 'meet-performance', '222dc7aa-7f87-408c-b8e4-9c237d44fb5b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (67309, '2019-10-13 01:28:18.688679', 'environment-hot', '616d31dc-139f-44a6-b200-3a4ffd79834f');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (27378, '2022-09-21 00:20:24.387332', 'pass-choose-will', '28959251-33ed-4bb4-8da7-6903704348f3');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (325, '2020-10-11 20:18:53.040586', 'leave-allow-others', 'a2fbe746-3bce-4e28-bce6-305775398857');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (36861, '2021-11-21 13:28:56.636748', 'become-today', 'ec1c09f2-9b79-48f9-b838-df6db4ec88f0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (88947, '2024-05-12 00:35:22.301089', 'note-meeting-bar', 'efe27982-b5c2-46fc-b287-8c61729e8a1c');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (39505, '2023-12-15 06:31:34.955745', 'idea-teacher-would', '8da77568-8b83-4d70-b872-a4d5472fa0c0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (23239, '2020-03-13 05:28:38.338495', 'history-big-station', '7836b471-3efd-4ccd-a61d-9de717a0051f');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (66980, '2020-06-23 00:54:48.738734', 'first-more-baby', '00891d6f-be15-40ea-96b5-b8035d6164e7');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (89498, '2023-12-14 23:39:12.696564', 'onto-now-his-nor', '379b0a29-14af-4779-90ed-6c97e9d9d92d');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (71298, '2022-03-31 09:30:28.774492', 'world-near-visit', 'deeae4e6-1fc3-40ed-9966-30bebaddeb5a');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (56167, '2020-08-20 23:47:05.461635', 'miss-five-lay-never', '448a00d4-b5ae-4d52-9a17-6bc0407ddae4');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (10276, '2023-12-03 09:45:20.970217', 'report-attack-right', '55020e0b-5c4e-40f9-942c-0b44529043a6');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (45941, '2021-11-28 16:19:35.948412', 'whatever-which', '222dc7aa-7f87-408c-b8e4-9c237d44fb5b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (72582, '2020-05-22 23:31:16.312553', 'rich-wind-lot-that', 'fd26ba43-dbba-4c33-9b7d-262f91e8b7a0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (52450, '2022-02-25 01:57:50.751057', 'head-executive', '525116b8-901b-4828-be03-c44bb3de3b3b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (189, '2022-11-02 09:33:50.948655', 'operation-health', 'ef61ef82-53f4-41ea-94e7-ad67f6379b91');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (51664, '2020-11-29 22:52:51.897747', 'deal-same-according', '379b0a29-14af-4779-90ed-6c97e9d9d92d');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (13325, '2020-12-30 01:01:50.271950', 'summer-field', 'efe27982-b5c2-46fc-b287-8c61729e8a1c');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (91537, '2023-02-10 06:17:01.907602', 'one-woman-animal', '30d3098d-a436-443b-a4fc-2529e74a0fa9');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (30391, '2022-01-24 08:07:56.246516', 'state-job-course', '50e2395d-31c4-4b13-ac82-1963b7ec3e8a');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (6035, '2020-05-29 22:45:14.954044', 'thought-arrive', 'ef61ef82-53f4-41ea-94e7-ad67f6379b91');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (20063, '2020-09-24 07:11:44.431197', 'leader-mrs-figure', 'ef61ef82-53f4-41ea-94e7-ad67f6379b91');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (71838, '2020-09-27 21:08:25.259468', 'return-arm-several', '90a76966-ecb9-4114-af3b-f23471ba5616');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (30163, '2024-06-16 04:52:18.677314', 'natural-left-story', 'ec1c09f2-9b79-48f9-b838-df6db4ec88f0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (27128, '2021-11-07 23:05:34.459393', 'organization-than', '448a00d4-b5ae-4d52-9a17-6bc0407ddae4');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (44185, '2021-07-23 04:34:19.933307', 'industry-leader', '97fdb7cc-4cbb-42ab-b0ad-4dabd22aca31');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (93337, '2021-09-01 17:43:30.562810', 'wall-sound-but-note', '6a731db3-a36d-4d47-983c-04c97b91630b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (56533, '2020-06-12 06:12:05.934041', 'play-under-practice', 'ec1c09f2-9b79-48f9-b838-df6db4ec88f0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (86588, '2023-10-06 19:01:07.180291', 'wall-suggest-turn', '8da77568-8b83-4d70-b872-a4d5472fa0c0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (60327, '2022-10-24 01:56:44.013445', 'tend-build-simple', 'b9d94cba-bde5-41bc-a634-720d65c23cfb');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (52745, '2021-12-17 07:32:59.019277', 'unit-painting-our', '30d3098d-a436-443b-a4fc-2529e74a0fa9');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (68649, '2024-04-04 12:14:02.987468', 'politics-middle', '55020e0b-5c4e-40f9-942c-0b44529043a6');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (93207, '2023-07-15 06:50:06.450265', 'only-worry-positive', '00891d6f-be15-40ea-96b5-b8035d6164e7');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (85531, '2022-09-18 06:45:13.687391', 'spend-score-perform', '4f0085e7-155b-4d46-9451-28e5e62ceb7e');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (89718, '2022-09-19 03:04:53.394402', 'pick-understand', '194ab5d9-1fd0-4ba2-83c9-eb920a47f84b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (24669, '2021-07-17 03:29:02.985954', 'impact-offer', 'efe27982-b5c2-46fc-b287-8c61729e8a1c');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (87023, '2019-12-16 22:20:34.613300', 'after-then-within', '7836b471-3efd-4ccd-a61d-9de717a0051f');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (22166, '2021-11-14 15:21:49.144113', 'election-better', 'fd26ba43-dbba-4c33-9b7d-262f91e8b7a0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (82868, '2023-09-21 00:34:23.777594', 'offer-trial', '8da77568-8b83-4d70-b872-a4d5472fa0c0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (16571, '2022-01-21 16:10:42.260021', 'dream-wear-finally', 'ec1c09f2-9b79-48f9-b838-df6db4ec88f0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (28400, '2023-07-10 15:26:59.785436', 'remember-among-kind', 'a2fbe746-3bce-4e28-bce6-305775398857');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (29889, '2021-07-03 05:31:43.548479', 'traditional-choice', '222dc7aa-7f87-408c-b8e4-9c237d44fb5b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (17512, '2023-05-05 16:35:13.471517', 'modern-office-some', 'ec1c09f2-9b79-48f9-b838-df6db4ec88f0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (51035, '2019-12-18 03:26:45.038981', 'could-reality-miss', '379b0a29-14af-4779-90ed-6c97e9d9d92d');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (59627, '2023-01-04 20:46:57.295161', 'accept-marriage', '6d074ed9-cfa9-4bbc-9be8-14ad71bb1330');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (30149, '2019-12-03 13:19:18.953340', 'east-movie-between', '3ac52e44-f864-423d-81fa-4c092d06369c');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (12409, '2021-11-07 16:17:18.083127', 'price-wish-fact', '4f0085e7-155b-4d46-9451-28e5e62ceb7e');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (35432, '2024-06-14 02:09:44.794580', 'less-serve', '1471c3bc-dc10-4d91-9918-271e6ffcf32a');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (68566, '2021-09-11 19:52:45.272986', 'stage-eat-east', '1471c3bc-dc10-4d91-9918-271e6ffcf32a');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (62611, '2021-05-14 20:57:16.836321', 'music-not-kid', '56a00eec-628a-465d-a5c0-5a9562cdbbf8');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (25532, '2024-02-24 06:44:10.990147', 'issue-ten', 'bfde79a0-19e4-42a6-93f0-aa33b5d0b16f');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (93875, '2021-08-18 16:25:41.962306', 'only-for-raise-name', '7836b471-3efd-4ccd-a61d-9de717a0051f');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (43742, '2020-12-31 10:37:34.457135', 'describe-return', '6a731db3-a36d-4d47-983c-04c97b91630b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (82869, '2019-11-24 05:42:17.307144', 'coach-manage-here', 'a2fbe746-3bce-4e28-bce6-305775398857');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (53550, '2020-10-19 19:42:46.511516', 'worker-police-along', '55020e0b-5c4e-40f9-942c-0b44529043a6');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (68085, '2019-10-17 10:36:50.744514', 'true-everyone-land', '55020e0b-5c4e-40f9-942c-0b44529043a6');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (61914, '2024-03-31 05:14:58.057353', 'election-beat-good', '8da77568-8b83-4d70-b872-a4d5472fa0c0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (28392, '2021-01-14 22:46:26.919398', 'offer-throw-occur', '194ab5d9-1fd0-4ba2-83c9-eb920a47f84b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (44458, '2020-09-03 06:53:39.310147', 'late-forward-firm', '00f2e429-83dc-4052-8643-e0c4d931bab2');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (98176, '2023-07-13 00:01:15.441537', 'morning-chair', '6a731db3-a36d-4d47-983c-04c97b91630b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (19763, '2022-05-02 14:53:30.866564', 'best-green-town', '22b3bfaf-f35c-4e40-90cf-87805c4a3c2d');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (36219, '2020-11-27 22:53:28.104114', 'daughter-modern', 'ef61ef82-53f4-41ea-94e7-ad67f6379b91');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (31071, '2022-03-14 18:36:44.059751', 'believe-large', 'deeae4e6-1fc3-40ed-9966-30bebaddeb5a');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (410, '2023-03-26 21:07:08.952724', 'season-happen', 'fd26ba43-dbba-4c33-9b7d-262f91e8b7a0');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (77734, '2022-04-11 06:18:47.817735', 'move-these-blood', 'b9d94cba-bde5-41bc-a634-720d65c23cfb');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (14244, '2023-03-10 01:54:51.800683', 'congress-during', 'b1bba5eb-2e94-4bac-9e8e-251b13c13ad3');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (20824, '2020-03-06 10:48:39.335374', 'society-image', '525116b8-901b-4828-be03-c44bb3de3b3b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (90103, '2020-12-03 15:28:03.753493', 'beyond-than-support', '28959251-33ed-4bb4-8da7-6903704348f3');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (99108, '2022-09-06 19:36:13.763351', 'we-teacher-he', '222dc7aa-7f87-408c-b8e4-9c237d44fb5b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (67523, '2022-05-11 18:28:19.590147', 'national-assume', '28959251-33ed-4bb4-8da7-6903704348f3');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (81395, '2020-08-14 14:51:08.888472', 'effect-however', '379b0a29-14af-4779-90ed-6c97e9d9d92d');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (92250, '2022-11-23 00:10:14.013508', 'president-professor', '379b0a29-14af-4779-90ed-6c97e9d9d92d');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (86781, '2020-04-06 05:16:35.671224', 'stuff-much-action', '525116b8-901b-4828-be03-c44bb3de3b3b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (28447, '2023-12-16 15:34:19.859106', 'morning-increase', 'deeae4e6-1fc3-40ed-9966-30bebaddeb5a');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (14588, '2022-04-29 13:21:14.385175', 'kitchen-beyond', '33c6593e-8697-4a67-b729-455cbc0d498b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (27285, '2020-01-26 21:01:33.279949', 'use-two-around-key', 'b1bba5eb-2e94-4bac-9e8e-251b13c13ad3');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (47791, '2021-05-19 00:19:29.767325', 'i-cause-myself', '291ecf4e-53e6-4227-80e3-7904e0f23368');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (24272, '2023-08-23 01:31:23.997519', 'decide-store-above', 'b1bba5eb-2e94-4bac-9e8e-251b13c13ad3');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (67312, '2021-11-26 16:59:11.131843', 'sister-star', '1471c3bc-dc10-4d91-9918-271e6ffcf32a');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (2834, '2022-05-28 09:17:42.976684', 'subject-stuff-left', '448a00d4-b5ae-4d52-9a17-6bc0407ddae4');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (10416, '2019-09-14 22:58:57.562240', 'inside-town', '4f0085e7-155b-4d46-9451-28e5e62ceb7e');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (86312, '2020-03-24 01:24:00.963407', 'hot-mr-standard', '56a00eec-628a-465d-a5c0-5a9562cdbbf8');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (32283, '2023-03-23 00:40:12.516776', 'enter-capital-good', '616d31dc-139f-44a6-b200-3a4ffd79834f');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (50581, '2021-04-13 02:30:24.165179', 'great-deep-give', '7836b471-3efd-4ccd-a61d-9de717a0051f');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (35873, '2024-01-22 23:04:29.293683', 'media-minute-page', '44ddfeaf-bee9-48b7-a554-ef09082f4088');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (54165, '2024-01-18 11:28:57.551250', 'project-social-data', '00f2e429-83dc-4052-8643-e0c4d931bab2');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (99123, '2022-01-18 18:07:24.079151', 'million-pretty', '97fdb7cc-4cbb-42ab-b0ad-4dabd22aca31');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (39593, '2022-10-16 13:32:15.357604', 'young-before-pull', '448a00d4-b5ae-4d52-9a17-6bc0407ddae4');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (42470, '2023-12-15 15:36:07.126564', 'wife-hour-three', 'b1bba5eb-2e94-4bac-9e8e-251b13c13ad3');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (85094, '2022-05-05 01:37:16.843638', 'what-economic-treat', '194ab5d9-1fd0-4ba2-83c9-eb920a47f84b');\nINSERT INTO channels (id, inserted_at, slug, created_by) VALUES (90768, '2020-01-15 13:51:39.705106', 'indeed-black', '4f0085e7-155b-4d46-9451-28e5e62ceb7e');\n\n-- messages\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (94829, '2021-11-18 13:04:06.597713', 'President not defense song drive. Total American significant out Republican share thus gas.', '00891d6f-be15-40ea-96b5-b8035d6164e7', 19763);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (62458, '2022-08-23 00:33:17.215169', 'Agree every rich together.', '8da77568-8b83-4d70-b872-a4d5472fa0c0', 30391);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (62048, '2024-05-22 10:33:44.088109', 'Tax deep know well.\nOffer by box necessary increase continue push.', '4f0085e7-155b-4d46-9451-28e5e62ceb7e', 93875);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (34834, '2021-12-13 12:23:09.500900', NULL, '90a76966-ecb9-4114-af3b-f23471ba5616', 27285);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (50407, '2023-08-07 14:17:15.536419', 'Food tell six beautiful. Meeting hot travel set see. Improve here approach today girl use book.', 'b1bba5eb-2e94-4bac-9e8e-251b13c13ad3', 28400);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (18740, '2021-07-16 21:37:58.483578', 'Reason each home church beat major. Power ask large this respond central.', '222dc7aa-7f87-408c-b8e4-9c237d44fb5b', 44763);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (69265, '2019-08-27 02:46:14.472327', NULL, '56a00eec-628a-465d-a5c0-5a9562cdbbf8', 28400);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (88099, '2021-02-16 16:55:41.204674', 'Add wrong sing able we follow. Save style cup foreign. Current like any.', '33c6593e-8697-4a67-b729-455cbc0d498b', 35432);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (55517, '2022-04-25 05:19:38.712064', 'Take stage son build Republican despite.', '448a00d4-b5ae-4d52-9a17-6bc0407ddae4', 56533);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (76685, '2021-12-12 02:16:43.536780', 'Former remain concern fish hear choice often. Minute year TV short year receive.', '56a00eec-628a-465d-a5c0-5a9562cdbbf8', 20824);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (88942, '2020-11-02 00:43:04.648724', 'Machine break president sit. How ask decision audience these office yard special.', 'ef61ef82-53f4-41ea-94e7-ad67f6379b91', 90103);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (15040, '2020-10-19 04:37:21.574757', 'Method kitchen three floor increase. Trouble law finally school economy.', '448a00d4-b5ae-4d52-9a17-6bc0407ddae4', 51664);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (87093, '2021-02-05 21:04:10.161199', 'Set television skin remain window for before. Manage reflect various treatment.', 'deeae4e6-1fc3-40ed-9966-30bebaddeb5a', 62758);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (4529, '2023-09-11 22:51:51.721073', 'Gun company build also fear. Boy weight institution scene party article film fall.', 'bfde79a0-19e4-42a6-93f0-aa33b5d0b16f', 29889);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (48614, '2021-06-23 02:55:00.286303', 'Likely collection ago throw group eat. Show say free window reason large.', '379b0a29-14af-4779-90ed-6c97e9d9d92d', 44763);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (45510, '2021-03-22 05:35:26.874110', NULL, '3ac52e44-f864-423d-81fa-4c092d06369c', 61443);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (41375, '2021-02-04 09:04:51.698930', 'Every find lot something make. Chance Congress state use popular.', '7836b471-3efd-4ccd-a61d-9de717a0051f', 68085);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (43201, '2024-04-26 16:55:19.388476', 'Sign important sell staff day. Main here standard weight. Their use nature model.', '194ab5d9-1fd0-4ba2-83c9-eb920a47f84b', 16571);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (14305, '2022-09-26 15:48:24.874145', 'Father executive media since. Approach while than hear teacher. Center off main possible prove.', '30d3098d-a436-443b-a4fc-2529e74a0fa9', 90768);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (41065, '2022-06-21 21:43:41.518341', 'Expert despite region college wall include. Experience apply nor stand risk.', '56a00eec-628a-465d-a5c0-5a9562cdbbf8', 23239);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (74148, '2020-01-10 12:16:15.430840', 'Ready happy hair purpose hand represent. Lay blood high give huge position.', '194ab5d9-1fd0-4ba2-83c9-eb920a47f84b', 14588);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (79178, '2021-07-24 09:12:08.450179', 'Him ever player themselves special agent letter yet. Yourself trouble peace over though.', 'b1bba5eb-2e94-4bac-9e8e-251b13c13ad3', 36219);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (84849, '2020-06-12 08:29:55.520926', 'Perhaps from marriage who finally. Policy ground which impact catch.', '525116b8-901b-4828-be03-c44bb3de3b3b', 92250);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (22983, '2020-12-10 08:06:53.142072', 'Quickly five figure example natural same. Very open human without fear. Fish worry sea prepare.', '28959251-33ed-4bb4-8da7-6903704348f3', 39593);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (20195, '2021-04-25 01:02:29.267352', 'Call than southern base. Dinner crime positive throughout look north. Social again theory director.', 'deeae4e6-1fc3-40ed-9966-30bebaddeb5a', 71838);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (32111, '2021-11-30 12:38:18.374103', 'Case author ever between necessary. Direction fund total Congress until policy stop economy.', 'deeae4e6-1fc3-40ed-9966-30bebaddeb5a', 99123);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (58071, '2023-03-22 00:50:48.148502', 'Glass pull collection. Organization and do development south require light.', '4f0085e7-155b-4d46-9451-28e5e62ceb7e', 77734);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (27386, '2020-05-29 05:52:53.740390', 'Food a business. College school ground approach election. Well statement high actually.', '56a00eec-628a-465d-a5c0-5a9562cdbbf8', 14244);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (4135, '2021-12-28 18:06:39.722119', 'Around sure try interesting expect reduce adult. Plan price hair movie determine crime.', 'deeae4e6-1fc3-40ed-9966-30bebaddeb5a', 26463);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (5891, '2021-01-09 23:55:07.136522', 'When yourself lawyer current sort task. Western happy whether account. Treatment old music cold.', '3ac52e44-f864-423d-81fa-4c092d06369c', 12409);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (35179, '2021-10-13 15:46:37.447123', 'Capital eight during begin pick thousand read. Four necessary film the.', '222dc7aa-7f87-408c-b8e4-9c237d44fb5b', 12409);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (5306, '2021-04-01 12:15:32.205757', 'Wife recently generation produce heart.', '33c6593e-8697-4a67-b729-455cbc0d498b', 93207);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (59160, '2023-02-14 15:43:50.376787', 'Little hot exist design. Provide choice born.', 'b1bba5eb-2e94-4bac-9e8e-251b13c13ad3', 89498);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (19237, '2022-01-22 00:50:53.240448', 'Yeah newspaper meeting plan. Set half describe. Become court table.', '8da77568-8b83-4d70-b872-a4d5472fa0c0', 90103);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (60640, '2022-04-29 13:45:54.910076', 'Job tonight at color light statement. Defense imagine material meet reflect.', '8da77568-8b83-4d70-b872-a4d5472fa0c0', 66980);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (65030, '2020-05-15 15:17:33.631718', 'Manage off poor. Include suggest mention top. Rise everybody candidate local.', '448a00d4-b5ae-4d52-9a17-6bc0407ddae4', 93630);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (72790, '2021-02-27 00:21:40.595679', 'Letter expert let tree environmental huge land avoid.\nMovie summer near attack next.', '448a00d4-b5ae-4d52-9a17-6bc0407ddae4', 82869);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (63137, '2019-09-22 04:34:35.341990', NULL, 'ef61ef82-53f4-41ea-94e7-ad67f6379b91', 62758);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (24400, '2022-08-14 03:45:10.347726', 'Key coach cut partner. Most free across notice skin. Common stand painting simple.', '6a731db3-a36d-4d47-983c-04c97b91630b', 86312);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (7024, '2023-08-23 13:34:22.749739', 'Color hard end result suggest. Newspaper free born begin.', '194ab5d9-1fd0-4ba2-83c9-eb920a47f84b', 93212);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (37547, '2021-08-01 19:19:22.498216', 'Ok range help accept American. Challenge standard produce property range song.', '55020e0b-5c4e-40f9-942c-0b44529043a6', 95748);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (48129, '2022-10-06 02:50:57.050759', 'Interest start pretty day shoulder in market. Foot these modern protect including forget garden.', '55020e0b-5c4e-40f9-942c-0b44529043a6', 38704);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (78395, '2022-02-18 07:22:15.841797', 'Mother lot choice study it. Have prepare stay clear black choose truth close.', '50e2395d-31c4-4b13-ac82-1963b7ec3e8a', 73167);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (67978, '2023-07-19 02:21:10.810202', 'Animal quickly understand section research issue. Smile bill different as project more.', '146a1828-e631-49f6-98f1-42d222b7931f', 73167);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (92790, '2023-06-04 10:33:16.189443', 'Medical party partner easy. Better type service serious.', '30d3098d-a436-443b-a4fc-2529e74a0fa9', 24272);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (24246, '2020-02-29 16:17:02.803081', 'Firm ask example guy goal degree. Tax class her section each star may job.', 'efe27982-b5c2-46fc-b287-8c61729e8a1c', 13325);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (95540, '2022-07-31 22:16:49.164415', 'Down once really. Sense recognize voice concern.', '56a00eec-628a-465d-a5c0-5a9562cdbbf8', 44763);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (54228, '2022-06-21 19:21:01.503431', NULL, '50e2395d-31c4-4b13-ac82-1963b7ec3e8a', 10416);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (4327, '2020-05-07 05:43:01.645906', NULL, '30d3098d-a436-443b-a4fc-2529e74a0fa9', 30163);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (99849, '2021-10-05 21:43:20.571702', 'List debate war instead. Father prove certain past.\nNecessary knowledge bring so despite dog.', 'a2fbe746-3bce-4e28-bce6-305775398857', 35873);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (57113, '2020-10-21 07:12:50.011332', 'Between smile better magazine. Style interesting man up majority soldier owner.', '146a1828-e631-49f6-98f1-42d222b7931f', 24499);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (83726, '2020-12-20 20:59:06.544979', 'Himself particular specific. Nearly you authority poor. Water build participant behind.', 'efe27982-b5c2-46fc-b287-8c61729e8a1c', 56533);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (76688, '2022-11-23 08:27:22.880867', NULL, 'deeae4e6-1fc3-40ed-9966-30bebaddeb5a', 92250);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (16261, '2020-10-21 08:59:09.636557', 'Manager why company say. Theory rich up play nation later. Run full economy might job.', '379b0a29-14af-4779-90ed-6c97e9d9d92d', 26048);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (90156, '2024-03-05 02:03:14.205370', NULL, '616d31dc-139f-44a6-b200-3a4ffd79834f', 67312);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (16093, '2022-06-25 05:45:18.031076', 'Much Democrat night modern. Would audience weight begin save family. Bring close reduce help.', 'ec1c09f2-9b79-48f9-b838-df6db4ec88f0', 24272);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (56701, '2022-09-16 18:58:36.301702', 'Sometimes apply foot spend organization pretty. Never woman yard now ask.', '33c6593e-8697-4a67-b729-455cbc0d498b', 86312);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (85764, '2023-06-04 09:49:05.363453', 'Pm system head rate despite thus. Participant behavior morning step.', '90a76966-ecb9-4114-af3b-f23471ba5616', 27128);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (13831, '2019-08-25 11:54:42.843190', 'Country see quality bad. Car home level it foreign. Paper move we join investment.', '50e2395d-31c4-4b13-ac82-1963b7ec3e8a', 36219);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (95177, '2020-01-24 07:11:37.463701', 'Behavior building rate own once. Language spring fine town every prevent name unit.', '222dc7aa-7f87-408c-b8e4-9c237d44fb5b', 86781);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (83295, '2022-03-17 02:30:12.620964', 'Often thing doctor state bar employee amount.', '30d3098d-a436-443b-a4fc-2529e74a0fa9', 36861);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (15873, '2023-10-27 00:45:44.025040', 'West ball local hope who up successful cell. Sometimes resource piece born.', '28959251-33ed-4bb4-8da7-6903704348f3', 71838);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (81716, '2022-08-08 00:33:36.679287', 'Rise century seven. Energy cold character process employee quality. Every long figure we.', 'ef61ef82-53f4-41ea-94e7-ad67f6379b91', 17512);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (49017, '2024-04-07 18:21:02.268999', 'Hotel fish reveal out thing know senior. Training rich contain senior.', '28959251-33ed-4bb4-8da7-6903704348f3', 47791);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (47786, '2023-08-30 20:33:23.228606', 'Head through five partner two old. Data level include return turn.', 'ec1c09f2-9b79-48f9-b838-df6db4ec88f0', 51366);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (68759, '2022-04-16 02:00:48.278659', 'Parent concern hand require lawyer moment. West right pull seven street.', '291ecf4e-53e6-4227-80e3-7904e0f23368', 53550);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (79768, '2022-09-09 11:33:12.720931', 'Will rule during force national green. Rather amount treat tax argue east. Car program simply.', 'deeae4e6-1fc3-40ed-9966-30bebaddeb5a', 12409);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (61389, '2023-06-06 20:39:48.632478', 'Agent bit live nation reveal.', 'b9d94cba-bde5-41bc-a634-720d65c23cfb', 92250);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (21994, '2021-08-30 06:54:20.623673', 'Of else plant collection reduce author.\nRule assume call under. Long design contain face.', 'b9d94cba-bde5-41bc-a634-720d65c23cfb', 87023);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (13869, '2021-05-05 15:00:10.359249', 'Research charge network near amount apply yourself. Reflect itself society quite some turn.', '30d3098d-a436-443b-a4fc-2529e74a0fa9', 23239);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (8967, '2021-07-22 05:33:42.737113', 'Night name skill Mr east. Song hope past successful rule claim of. Real experience should network.', 'a2fbe746-3bce-4e28-bce6-305775398857', 71838);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (23113, '2022-06-05 14:34:46.890886', 'Car dream indicate actually at line.', '7836b471-3efd-4ccd-a61d-9de717a0051f', 35432);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (92209, '2023-04-17 14:05:25.187421', 'Talk evening performance. Relationship star air teacher require decision.', 'b9d94cba-bde5-41bc-a634-720d65c23cfb', 86781);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (75522, '2021-03-07 18:21:26.112487', 'Fly challenge camera sell physical analysis time. Business house exist control.', 'deeae4e6-1fc3-40ed-9966-30bebaddeb5a', 189);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (87427, '2024-02-24 00:23:44.322691', 'Hard shoulder challenge. Town put nation four middle my authority.', '1471c3bc-dc10-4d91-9918-271e6ffcf32a', 44763);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (57630, '2023-12-05 12:13:43.520500', 'Upon get three relate interview. Guy system picture onto or.', '6d074ed9-cfa9-4bbc-9be8-14ad71bb1330', 71298);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (17791, '2023-01-30 20:16:39.331593', 'Buy south this central hear. Bring especially play skin far role pattern.', '22b3bfaf-f35c-4e40-90cf-87805c4a3c2d', 93875);\nINSERT INTO messages (id, inserted_at, message, user_id, channel_id) VALUES (92282, '2023-08-16 17:29:36.931592', 'Cause middle sense million outside all after. South order believe available.', 'bfde79a0-19e4-42a6-93f0-aa33b5d0b16f', 22166);\n</code></pre>"},{"location":"examples/add-seed-sql-data/#future-improvements","title":"Future Improvements","text":"<ul> <li>Add support for more SQL databases.</li> <li>Add support for more complex date setting (e.g., created_date vs last_updated).</li> <li>~~Add support for more complex datatypes, for instance recognizing and mimicking emails or usernames.~~</li> </ul>"},{"location":"examples/add-seed-sql-data/#conclusion","title":"Conclusion","text":"<p>You have successfully generated seed data for your SQL database using the <code>--seed</code> option with <code>supabase-pydantic</code>. This feature is very useful when you need to populate your database with test data or test your application with a large dataset &amp; Pydantic models.</p> <p></p>"},{"location":"examples/enum-model-generation/","title":"Generating Pydantic Models with Cross-Schema Enums","text":"<p>This guide demonstrates how to use <code>sb-pydantic</code> to generate Pydantic models with proper enum support when enums are defined in one schema but used in views from another schema. This is a common pattern where you have your core data tables in the <code>public</code> schema but expose API views in a separate <code>api</code> schema.</p>"},{"location":"examples/enum-model-generation/#overview","title":"Overview","text":"<p>In this example, we'll create: - Enums and tables in the <code>public</code> schema - Views in the <code>api</code> schema that reference the enums from <code>public</code> - Pydantic models generated from the <code>api</code> schema that properly use the cross-schema enums</p>"},{"location":"examples/enum-model-generation/#step-1-database-setup-script","title":"Step 1: Database Setup Script","text":"<p>Run this SQL script to set up the test database structure:</p> <pre><code>-- Create schemas\nCREATE SCHEMA IF NOT EXISTS public;\nCREATE SCHEMA IF NOT EXISTS api;\n\n-- Create enum types in the public schema\nCREATE TYPE public.order_status AS ENUM ('pending', 'processing', 'shipped', 'delivered', 'cancelled');\nCREATE TYPE public.user_role AS ENUM ('admin', 'user', 'moderator');\n\n-- Create tables in the public schema\nCREATE TABLE public.users (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(100) NOT NULL,\n    email VARCHAR(255) UNIQUE NOT NULL,\n    role public.user_role DEFAULT 'user',\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE public.orders (\n    id SERIAL PRIMARY KEY,\n    user_id INTEGER REFERENCES public.users(id),\n    status public.order_status DEFAULT 'pending',\n    total_amount DECIMAL(10,2),\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Insert some test data\nINSERT INTO public.users (name, email, role) VALUES \n    ('John Doe', 'john@example.com', 'user'),\n    ('Jane Admin', 'jane@example.com', 'admin'),\n    ('Bob Moderator', 'bob@example.com', 'moderator');\n\nINSERT INTO public.orders (user_id, status, total_amount) VALUES \n    (1, 'pending', 99.99),\n    (1, 'processing', 149.50),\n    (2, 'shipped', 299.00),\n    (3, 'delivered', 75.25);\n\n-- Create views in the api schema that use the enums from public schema\nCREATE VIEW api.user_profiles AS\nSELECT \n    id,\n    name,\n    email,\n    role,  -- This uses public.user_role enum\n    created_at\nFROM public.users;\n\nCREATE VIEW api.order_summary AS\nSELECT \n    o.id,\n    o.status,  -- This uses public.order_status enum\n    o.total_amount,\n    u.name as customer_name,\n    u.email as customer_email,\n    o.created_at\nFROM public.orders o\nJOIN public.users u ON o.user_id = u.id;\n\n-- Create a view with array of enums to test array handling\nCREATE VIEW api.order_status_options AS\nSELECT \n    ARRAY['pending', 'processing', 'shipped', 'delivered', 'cancelled']::public.order_status[] as available_statuses,\n    'Order Status Options' as description;\n</code></pre> <pre><code>sb-pydantic gen --type pydantic --framework fastapi --local --schema public --schema api\n</code></pre> <p>This command generates models for both the <code>public</code> and <code>api</code> schemas, allowing the cross-schema enum references to be properly resolved.</p>"},{"location":"examples/enum-model-generation/#step-3-generated-output","title":"Step 3: Generated Output","text":"<p>The command will generate a file <code>schema_api_latest.py</code> that includes:</p>"},{"location":"examples/enum-model-generation/#enum-classes","title":"Enum Classes","text":"<p>Notice how the enums are prefixed with their schema name:</p> <pre><code>class PublicOrderStatusEnum(str, Enum):\n    PENDING = 'pending'\n    PROCESSING = 'processing'\n    SHIPPED = 'shipped'\n    DELIVERED = 'delivered'\n    CANCELLED = 'cancelled'\n\nclass PublicUserRoleEnum(str, Enum):\n    ADMIN = 'admin'\n    USER = 'user'\n    MODERATOR = 'moderator'\n</code></pre>"},{"location":"examples/enum-model-generation/#model-classes-with-cross-schema-enums","title":"Model Classes with Cross-Schema Enums","text":"<p>The views from the <code>api</code> schema properly reference enums from the <code>public</code> schema:</p> <pre><code>class UserProfilesBaseSchema(CustomModel):\n    \"\"\"UserProfiles Base Schema.\"\"\"\n\n    created_at: datetime.datetime | None = Field(default=None)\n    email: str | None = Field(default=None)\n    id: int | None = Field(default=None)\n    name: str | None = Field(default=None)\n    role: PublicUserRoleEnum | None = Field(default=None)  # Cross-schema enum!\n\nclass OrderSummaryBaseSchema(CustomModel):\n    \"\"\"OrderSummary Base Schema.\"\"\"\n\n    created_at: datetime.datetime | None = Field(default=None)\n    customer_email: str | None = Field(default=None)\n    customer_name: str | None = Field(default=None)\n    id: int | None = Field(default=None)\n    status: PublicOrderStatusEnum | None = Field(default=None)  # Cross-schema enum!\n    total_amount: Decimal | None = Field(default=None)\n\nclass OrderStatusOptionsBaseSchema(CustomModel):\n    \"\"\"OrderStatusOptions Base Schema.\"\"\"\n\n    available_statuses: list[PublicOrderStatusEnum] | None = Field(default=None)  # Array of enums!\n    description: str | None = Field(default=None)\n</code></pre>"},{"location":"examples/enum-model-generation/#step-4-key-features-demonstrated","title":"Step 4: Key Features Demonstrated","text":"<p>This example showcases several important features:</p> <ol> <li>Cross-Schema Enum Discovery: Enums defined in <code>public</code> are properly detected and used in <code>api</code> views</li> <li>Schema-Prefixed Naming: Enum classes are named <code>PublicOrderStatusEnum</code> to indicate their origin schema</li> <li>Array Support: The <code>available_statuses</code> field shows proper handling of enum arrays</li> <li>View Support: Database views are treated the same as tables for model generation</li> </ol>"},{"location":"examples/enum-model-generation/#step-5-cleanup-script","title":"Step 5: Cleanup Script","text":"<p>When you're done testing, run this cleanup script:</p> <pre><code>-- Drop views in the api schema\nDROP VIEW IF EXISTS api.order_status_options;\nDROP VIEW IF EXISTS api.order_summary;\nDROP VIEW IF EXISTS api.user_profiles;\n\n-- Drop tables in the public schema (this will cascade to dependent objects)\nDROP TABLE IF EXISTS public.orders CASCADE;\nDROP TABLE IF EXISTS public.users CASCADE;\n\n-- Drop enum types in the public schema\nDROP TYPE IF EXISTS public.order_status CASCADE;\nDROP TYPE IF EXISTS public.user_role CASCADE;\n\n-- Drop the api schema (if it was created just for testing)\nDROP SCHEMA IF EXISTS api CASCADE;\n</code></pre>"},{"location":"examples/enum-model-generation/#notes","title":"Notes","text":"<ul> <li>Schema Prefixing: Notice how enum classes are prefixed with their origin schema (<code>PublicOrderStatusEnum</code>) to avoid naming conflicts</li> <li>Cross-Schema References: Views in the <code>api</code> schema can seamlessly use enums defined in the <code>public</code> schema</li> <li>Array Handling: Enum arrays are properly typed as <code>list[EnumType]</code></li> <li>Backward Compatibility: This feature works alongside existing single-schema setups without any breaking changes</li> </ul> <p>This cross-schema enum support makes it easy to maintain clean separation between your data layer (<code>public</code>) and API layer (<code>api</code>) while still getting full type safety in your Pydantic models.</p>"},{"location":"examples/generate-multiple-basemodels/","title":"Generate Multiple BaseModels for Multiple Schemas","text":"<p>This example demonstrates how to generate multiple BaseModel files corresponding to multiple database schemas. The <code>--all-schemas</code> option with <code>supabase-pydantic</code> allows the generation of BaseModel files for all schemas that are not empty. Additionally, the <code>--schema</code> option can be used to specify a specific schema to generate a BaseModel file for. The default behavior is to generate a BaseModel file for the <code>public</code> schema if neither of these option is provided. This feature is useful when you want to create Pydantic models for schemas other than <code>public</code> in your database.</p> <p>Please note ...</p> <p>This is a developing feature . It is imperfect, so please report any issues you encounter.</p>"},{"location":"examples/generate-multiple-basemodels/#prerequisites","title":"Prerequisites","text":"<p>Ensure that you have followed the setup &amp; prerequisites guide in the Slack Clone example to initialize your local Supabase instance.</p>"},{"location":"examples/generate-multiple-basemodels/#generating-basemodels-for-a-specific-schema","title":"Generating BaseModels for a Specific Schema","text":"<p>To generate a BaseModel file for a specific schema, use one or more <code>--schema</code> options with the <code>generate</code> command. For example, run the following command:</p> Generate BaseModel for a Specific Schema<pre><code>$ sb-pydantic gen --type pydantic --framework fastapi --local --schema public --schema auth --schema extensions\n\n2023-07-15 14:22:10 - INFO - PostGres connection is open.\n2023-07-15 14:22:11 - INFO - Processing schema: public\n2023-07-15 14:22:11 - INFO - Processing schema: auth\n2023-07-15 14:22:11 - INFO - Processing schema: extensions\n2023-07-15 14:22:12 - INFO - PostGres connection is closed.\n2023-07-15 14:22:12 - INFO - Generating Pydantic models...\n2023-07-15 14:22:14 - INFO - Pydantic models generated successfully for schema 'auth': /path/to/your/project/entities/fastapi/schema_auth_latest.py\n2023-07-15 14:22:14 - INFO - Generating Pydantic models...\n2023-07-15 14:22:16 - INFO - Pydantic models generated successfully for schema 'extensions': /path/to/your/project/entities/fastapi/schema_extensions_latest.py\n2023-07-15 14:22:16 - INFO - Generating Pydantic models...\n2023-07-15 14:22:18 - INFO - Pydantic models generated successfully for schema 'public': /path/to/your/project/entities/fastapi/schema_public_latest.py\n2023-07-15 14:22:18 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_auth_latest.py\n2023-07-15 14:22:18 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_extensions_latest.py\n2023-07-15 14:22:19 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_public_latest.py\n</code></pre> <p>An example of the generated BaseModel file for the <code>auth</code> schema can be found here: </p> schema_auth_latest.py <pre><code>from __future__ import annotations\n\nimport datetime\nfrom ipaddress import IPv4Address, IPv6Address\n\nfrom pydantic import UUID4, BaseModel, Field, Json\n\n# CUSTOM CLASSES\n# Note: This is a custom model class for defining common features among\n# Pydantic Base Schema.\n\n\nclass CustomModel(BaseModel):\n    pass\n\n\n# BASE CLASSES\n\n\nclass AuditLogEntriesBaseSchema(CustomModel):\n    \"\"\"AuditLogEntries Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    created_at: datetime.datetime | None = Field(default=None)\n    instance_id: UUID4 | None = Field(default=None)\n    ip_address: str\n    payload: dict | list[dict] | list[Any] | Json | None = Field(default=None)\n\n\nclass FlowStateBaseSchema(CustomModel):\n    \"\"\"FlowState Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    auth_code: str\n    auth_code_issued_at: datetime.datetime | None = Field(default=None)\n    authentication_method: str\n    code_challenge: str\n    code_challenge_method: str\n    created_at: datetime.datetime | None = Field(default=None)\n    provider_access_token: str | None = Field(default=None)\n    provider_refresh_token: str | None = Field(default=None)\n    provider_type: str\n    updated_at: datetime.datetime | None = Field(default=None)\n    user_id: UUID4 | None = Field(default=None)\n\n\nclass IdentitiesBaseSchema(CustomModel):\n    \"\"\"Identities Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    created_at: datetime.datetime | None = Field(default=None)\n    email: str | None = Field(default=None)\n    identity_data: dict | list[dict] | list[Any] | Json\n    last_sign_in_at: datetime.datetime | None = Field(default=None)\n    provider: str\n    provider_id: str\n    updated_at: datetime.datetime | None = Field(default=None)\n    user_id: UUID4\n\n\nclass InstancesBaseSchema(CustomModel):\n    \"\"\"Instances Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    created_at: datetime.datetime | None = Field(default=None)\n    raw_base_config: str | None = Field(default=None)\n    updated_at: datetime.datetime | None = Field(default=None)\n    uuid: UUID4 | None = Field(default=None)\n\n\nclass MfaAmrClaimsBaseSchema(CustomModel):\n    \"\"\"MfaAmrClaims Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    authentication_method: str\n    created_at: datetime.datetime\n    session_id: UUID4\n    updated_at: datetime.datetime\n\n\nclass MfaChallengesBaseSchema(CustomModel):\n    \"\"\"MfaChallenges Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    created_at: datetime.datetime\n    factor_id: UUID4\n    ip_address: IPv4Address | IPv6Address\n    otp_code: str | None = Field(default=None)\n    verified_at: datetime.datetime | None = Field(default=None)\n\n\nclass MfaFactorsBaseSchema(CustomModel):\n    \"\"\"MfaFactors Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    created_at: datetime.datetime\n    factor_type: str\n    friendly_name: str | None = Field(default=None)\n    last_challenged_at: datetime.datetime | None = Field(default=None)\n    phone: str | None = Field(default=None)\n    secret: str | None = Field(default=None)\n    status: str\n    updated_at: datetime.datetime\n    user_id: UUID4\n\n\nclass OneTimeTokensBaseSchema(CustomModel):\n    \"\"\"OneTimeTokens Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    created_at: datetime.datetime\n    relates_to: str\n    token_hash: str\n    token_type: str\n    updated_at: datetime.datetime\n    user_id: UUID4\n\n\nclass RefreshTokensBaseSchema(CustomModel):\n    \"\"\"RefreshTokens Base Schema.\"\"\"\n\n    # Primary Keys\n    id: int\n\n    # Columns\n    created_at: datetime.datetime | None = Field(default=None)\n    instance_id: UUID4 | None = Field(default=None)\n    parent: str | None = Field(default=None)\n    revoked: bool | None = Field(default=None)\n    session_id: UUID4 | None = Field(default=None)\n    token: str | None = Field(default=None)\n    updated_at: datetime.datetime | None = Field(default=None)\n    user_id: str | None = Field(default=None)\n\n\nclass SamlProvidersBaseSchema(CustomModel):\n    \"\"\"SamlProviders Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    attribute_mapping: dict | list[dict] | list[Any] | Json | None = Field(default=None)\n    created_at: datetime.datetime | None = Field(default=None)\n    entity_id: str\n    metadata_url: str | None = Field(default=None)\n    metadata_xml: str\n    name_id_format: str | None = Field(default=None)\n    sso_provider_id: UUID4\n    updated_at: datetime.datetime | None = Field(default=None)\n\n\nclass SamlRelayStatesBaseSchema(CustomModel):\n    \"\"\"SamlRelayStates Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    created_at: datetime.datetime | None = Field(default=None)\n    flow_state_id: UUID4 | None = Field(default=None)\n    for_email: str | None = Field(default=None)\n    redirect_to: str | None = Field(default=None)\n    request_id: str\n    sso_provider_id: UUID4\n    updated_at: datetime.datetime | None = Field(default=None)\n\n\nclass SchemaMigrationsBaseSchema(CustomModel):\n    \"\"\"SchemaMigrations Base Schema.\"\"\"\n\n    # Primary Keys\n    version: str\n\n\nclass SessionsBaseSchema(CustomModel):\n    \"\"\"Sessions Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    aal: str | None = Field(default=None)\n    created_at: datetime.datetime | None = Field(default=None)\n    factor_id: UUID4 | None = Field(default=None)\n    ip: IPv4Address | IPv6Address | None = Field(default=None)\n    not_after: datetime.datetime | None = Field(default=None)\n    refreshed_at: datetime.datetime | None = Field(default=None)\n    tag: str | None = Field(default=None)\n    updated_at: datetime.datetime | None = Field(default=None)\n    user_agent: str | None = Field(default=None)\n    user_id: UUID4\n\n\nclass SsoDomainsBaseSchema(CustomModel):\n    \"\"\"SsoDomains Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    created_at: datetime.datetime | None = Field(default=None)\n    domain: str\n    sso_provider_id: UUID4\n    updated_at: datetime.datetime | None = Field(default=None)\n\n\nclass SsoProvidersBaseSchema(CustomModel):\n    \"\"\"SsoProviders Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    created_at: datetime.datetime | None = Field(default=None)\n    resource_id: str | None = Field(default=None)\n    updated_at: datetime.datetime | None = Field(default=None)\n\n\nclass UsersBaseSchema(CustomModel):\n    \"\"\"Users Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    aud: str | None = Field(default=None)\n    banned_until: datetime.datetime | None = Field(default=None)\n    confirmation_sent_at: datetime.datetime | None = Field(default=None)\n    confirmation_token: str | None = Field(default=None)\n    confirmed_at: datetime.datetime | None = Field(default=None)\n    created_at: datetime.datetime | None = Field(default=None)\n    deleted_at: datetime.datetime | None = Field(default=None)\n    email: str | None = Field(default=None)\n    email_change: str | None = Field(default=None)\n    email_change_confirm_status: int | None = Field(default=None)\n    email_change_sent_at: datetime.datetime | None = Field(default=None)\n    email_change_token_current: str | None = Field(default=None)\n    email_change_token_new: str | None = Field(default=None)\n    email_confirmed_at: datetime.datetime | None = Field(default=None)\n    encrypted_password: str | None = Field(default=None)\n    instance_id: UUID4 | None = Field(default=None)\n    invited_at: datetime.datetime | None = Field(default=None)\n    is_anonymous: bool\n    is_sso_user: bool\n    is_super_admin: bool | None = Field(default=None)\n    last_sign_in_at: datetime.datetime | None = Field(default=None)\n    phone: str | None = Field(default=None)\n    phone_change: str | None = Field(default=None)\n    phone_change_sent_at: datetime.datetime | None = Field(default=None)\n    phone_change_token: str | None = Field(default=None)\n    phone_confirmed_at: datetime.datetime | None = Field(default=None)\n    raw_app_meta_data: dict | list[dict] | list[Any] | Json | None = Field(default=None)\n    raw_user_meta_data: dict | list[dict] | list[Any] | Json | None = Field(default=None)\n    reauthentication_sent_at: datetime.datetime | None = Field(default=None)\n    reauthentication_token: str | None = Field(default=None)\n    recovery_sent_at: datetime.datetime | None = Field(default=None)\n    recovery_token: str | None = Field(default=None)\n    role: str | None = Field(default=None)\n    updated_at: datetime.datetime | None = Field(default=None)\n\n\n# OPERATIONAL CLASSES\n\n\nclass AuditLogEntries(AuditLogEntriesBaseSchema):\n    \"\"\"AuditLogEntries Schema for Pydantic.\n\n    Inherits from AuditLogEntriesBaseSchema. Add any customization here.\n    \"\"\"\n\n    pass\n\n\nclass FlowState(FlowStateBaseSchema):\n    \"\"\"FlowState Schema for Pydantic.\n\n    Inherits from FlowStateBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    saml_relay_states: list[SamlRelayStates] | None = Field(default=None)\n\n\nclass Identities(IdentitiesBaseSchema):\n    \"\"\"Identities Schema for Pydantic.\n\n    Inherits from IdentitiesBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    users: list[Users] | None = Field(default=None)\n\n\nclass Instances(InstancesBaseSchema):\n    \"\"\"Instances Schema for Pydantic.\n\n    Inherits from InstancesBaseSchema. Add any customization here.\n    \"\"\"\n\n    pass\n\n\nclass MfaAmrClaims(MfaAmrClaimsBaseSchema):\n    \"\"\"MfaAmrClaims Schema for Pydantic.\n\n    Inherits from MfaAmrClaimsBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    sessions: list[Sessions] | None = Field(default=None)\n\n\nclass MfaChallenges(MfaChallengesBaseSchema):\n    \"\"\"MfaChallenges Schema for Pydantic.\n\n    Inherits from MfaChallengesBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    mfa_factors: list[MfaFactors] | None = Field(default=None)\n\n\nclass MfaFactors(MfaFactorsBaseSchema):\n    \"\"\"MfaFactors Schema for Pydantic.\n\n    Inherits from MfaFactorsBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    users: list[Users] | None = Field(default=None)\n    mfa_challenges: list[MfaChallenges] | None = Field(default=None)\n\n\nclass OneTimeTokens(OneTimeTokensBaseSchema):\n    \"\"\"OneTimeTokens Schema for Pydantic.\n\n    Inherits from OneTimeTokensBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    users: list[Users] | None = Field(default=None)\n\n\nclass RefreshTokens(RefreshTokensBaseSchema):\n    \"\"\"RefreshTokens Schema for Pydantic.\n\n    Inherits from RefreshTokensBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    sessions: list[Sessions] | None = Field(default=None)\n\n\nclass SamlProviders(SamlProvidersBaseSchema):\n    \"\"\"SamlProviders Schema for Pydantic.\n\n    Inherits from SamlProvidersBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    sso_providers: list[SsoProviders] | None = Field(default=None)\n\n\nclass SamlRelayStates(SamlRelayStatesBaseSchema):\n    \"\"\"SamlRelayStates Schema for Pydantic.\n\n    Inherits from SamlRelayStatesBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    flow_state: list[FlowState] | None = Field(default=None)\n    sso_providers: list[SsoProviders] | None = Field(default=None)\n\n\nclass SchemaMigrations(SchemaMigrationsBaseSchema):\n    \"\"\"SchemaMigrations Schema for Pydantic.\n\n    Inherits from SchemaMigrationsBaseSchema. Add any customization here.\n    \"\"\"\n\n    pass\n\n\nclass Sessions(SessionsBaseSchema):\n    \"\"\"Sessions Schema for Pydantic.\n\n    Inherits from SessionsBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    users: list[Users] | None = Field(default=None)\n    mfa_amr_claims: list[MfaAmrClaims] | None = Field(default=None)\n    refresh_tokens: list[RefreshTokens] | None = Field(default=None)\n\n\nclass SsoDomains(SsoDomainsBaseSchema):\n    \"\"\"SsoDomains Schema for Pydantic.\n\n    Inherits from SsoDomainsBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    sso_providers: list[SsoProviders] | None = Field(default=None)\n\n\nclass SsoProviders(SsoProvidersBaseSchema):\n    \"\"\"SsoProviders Schema for Pydantic.\n\n    Inherits from SsoProvidersBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    saml_providers: list[SamlProviders] | None = Field(default=None)\n    saml_relay_states: list[SamlRelayStates] | None = Field(default=None)\n    sso_domains: list[SsoDomains] | None = Field(default=None)\n\n\nclass Users(UsersBaseSchema):\n    \"\"\"Users Schema for Pydantic.\n\n    Inherits from UsersBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    identities: list[Identities] | None = Field(default=None)\n    mfa_factors: list[MfaFactors] | None = Field(default=None)\n    one_time_tokens: list[OneTimeTokens] | None = Field(default=None)\n    sessions: list[Sessions] | None = Field(default=None)\n</code></pre>"},{"location":"examples/generate-multiple-basemodels/#generating-basemodels-for-all-schemas","title":"Generating BaseModels for All Schemas","text":"<p>To generate BaseModel files for all schemas, use the <code>--all-schemas</code> option with the <code>generate</code> command. Note, this will take precedence over any <code>--schema</code> options provided. For example, run the following command:</p> Generate BaseModels for All Schemas<pre><code>$ sb-pydantic gen --type pydantic --framework fastapi --local --all-schemas\n\n2023-07-15 14:30:05 - INFO - PostGres connection is open.\n2023-07-15 14:30:06 - INFO - Processing schema: public\n2023-07-15 14:30:06 - INFO - Processing schema: graphql\n2023-07-15 14:30:06 - INFO - Processing schema: graphql_public\n2023-07-15 14:30:06 - INFO - Processing schema: vault\n2023-07-15 14:30:06 - INFO - Processing schema: pgsodium_masks\n2023-07-15 14:30:06 - INFO - Processing schema: pgsodium\n2023-07-15 14:30:07 - INFO - Processing schema: auth\n2023-07-15 14:30:07 - INFO - Processing schema: storage\n2023-07-15 14:30:07 - INFO - Processing schema: realtime\n2023-07-15 14:30:07 - INFO - Processing schema: net\n2023-07-15 14:30:07 - INFO - Processing schema: supabase_functions\n2023-07-15 14:30:07 - INFO - Processing schema: pg_toast_temp_20\n2023-07-15 14:30:07 - INFO - Processing schema: pg_temp_20\n2023-07-15 14:30:08 - INFO - Processing schema: pg_toast_temp_27\n2023-07-15 14:30:08 - INFO - Processing schema: pg_temp_27\n2023-07-15 14:30:08 - INFO - Processing schema: pg_toast_temp_19\n2023-07-15 14:30:08 - INFO - Processing schema: pg_temp_19\n2023-07-15 14:30:08 - INFO - Processing schema: _supavisor\n2023-07-15 14:30:08 - INFO - Processing schema: _analytics\n2023-07-15 14:30:08 - INFO - Processing schema: _realtime\n2023-07-15 14:30:08 - INFO - Processing schema: pg_toast_temp_31\n2023-07-15 14:30:09 - INFO - Processing schema: pg_temp_31\n2023-07-15 14:30:09 - INFO - Processing schema: pg_toast_temp_30\n2023-07-15 14:30:09 - INFO - Processing schema: pg_temp_30\n2023-07-15 14:30:09 - INFO - Processing schema: pg_toast_temp_32\n2023-07-15 14:30:09 - INFO - Processing schema: pg_temp_32\n2023-07-15 14:30:09 - INFO - Processing schema: pg_toast_temp_28\n2023-07-15 14:30:09 - INFO - Processing schema: extensions\n2023-07-15 14:30:09 - INFO - Processing schema: pg_temp_28\n2023-07-15 14:30:10 - INFO - Processing schema: pg_toast_temp_29\n2023-07-15 14:30:10 - INFO - Processing schema: pg_temp_29\n2023-07-15 14:30:10 - INFO - Processing schema: pg_toast\n2023-07-15 14:30:10 - INFO - PostGres connection is closed.\n2023-07-15 14:30:10 - INFO - The following schemas have no tables and will be skipped: graphql, graphql_public, pgsodium_masks, pg_toast_temp_20, pg_temp_20, pg_toast_temp_27, pg_temp_27, pg_toast_temp_19, pg_temp_19, _supavisor, _realtime, pg_toast_temp_31, pg_temp_31, pg_toast_temp_30, pg_temp_30, pg_toast_temp_32, pg_temp_32, pg_toast_temp_28, pg_temp_28, pg_toast_temp_29, pg_temp_29, pg_toast\n2023-07-15 14:30:10 - INFO - Generating Pydantic models...\n2023-07-15 14:30:12 - INFO - Pydantic models generated successfully for schema 'public': /path/to/your/project/entities/fastapi/schema_public_latest.py\n2023-07-15 14:30:12 - INFO - Generating Pydantic models...\n2023-07-15 14:30:14 - INFO - Pydantic models generated successfully for schema 'vault': /path/to/your/project/entities/fastapi/schema_vault_latest.py\n2023-07-15 14:30:14 - INFO - Generating Pydantic models...\n2023-07-15 14:30:15 - INFO - Pydantic models generated successfully for schema 'pgsodium': /path/to/your/project/entities/fastapi/schema_pgsodium_latest.py\n2023-07-15 14:30:15 - INFO - Generating Pydantic models...\n2023-07-15 14:30:17 - INFO - Pydantic models generated successfully for schema 'auth': /path/to/your/project/entities/fastapi/schema_auth_latest.py\n2023-07-15 14:30:17 - INFO - Generating Pydantic models...\n2023-07-15 14:30:19 - INFO - Pydantic models generated successfully for schema 'storage': /path/to/your/project/entities/fastapi/schema_storage_latest.py\n2023-07-15 14:30:19 - INFO - Generating Pydantic models...\n2023-07-15 14:30:20 - INFO - Pydantic models generated successfully for schema 'realtime': /path/to/your/project/entities/fastapi/schema_realtime_latest.py\n2023-07-15 14:30:20 - INFO - Generating Pydantic models...\n2023-07-15 14:30:22 - INFO - Pydantic models generated successfully for schema 'net': /path/to/your/project/entities/fastapi/schema_net_latest.py\n2023-07-15 14:30:22 - INFO - Generating Pydantic models...\n2023-07-15 14:30:24 - INFO - Pydantic models generated successfully for schema 'supabase_functions': /path/to/your/project/entities/fastapi/schema_supabase_functions_latest.py\n2023-07-15 14:30:24 - INFO - Generating Pydantic models...\n2023-07-15 14:30:26 - INFO - Pydantic models generated successfully for schema '_analytics': /path/to/your/project/entities/fastapi/schema__analytics_latest.py\n2023-07-15 14:30:26 - INFO - Generating Pydantic models...\n2023-07-15 14:30:28 - INFO - Pydantic models generated successfully for schema 'extensions': /path/to/your/project/entities/fastapi/schema_extensions_latest.py\n2023-07-15 14:30:28 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_public_latest.py\n2023-07-15 14:30:28 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_vault_latest.py\n2023-07-15 14:30:28 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_pgsodium_latest.py\n2023-07-15 14:30:29 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_auth_latest.py\n2023-07-15 14:30:29 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_storage_latest.py\n2023-07-15 14:30:29 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_realtime_latest.py\n2023-07-15 14:30:29 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_net_latest.py\n2023-07-15 14:30:29 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_supabase_functions_latest.py\n2023-07-15 14:30:29 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema__analytics_latest.py\n2023-07-15 14:30:30 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schema_extensions_latest.py\n</code></pre> <p>Note that each schema will have its own BaseModel file generated in the <code>entities</code> directory of your project. As a result, each will have a prepended <code>schema_</code> prefix and a <code>_latest</code> suffix, with the name of the corresponding schema.</p>"},{"location":"examples/generate-multiple-basemodels/#conclusion","title":"Conclusion","text":"<p>Using the <code>--schema</code> option with the <code>generate</code> command makes it easy to generate Pydantic models for select database schemas. The <code>--all-schemas</code> option is particularly useful if you want to create models for every schema without specifying each one individually.</p> <p>Please note that some of the following features which will be created in future releases:</p> <ul> <li>Enable better foreign table key linking for relationships with foreign schemas.</li> </ul> <p></p>"},{"location":"examples/insert-update-models/","title":"Working with Insert and Update Models","text":"<p>This guide demonstrates how to work with the automatically generated Insert and Update models in <code>supabase-pydantic</code>. These models are specifically designed to handle the different requirements for inserting new records and updating existing ones in your Supabase database.</p> <p>Alignment with Supabase TypeScript Types</p> <p>This feature aligns with Supabase's TypeScript type generation, which generates three types for each table: <code>Database['public']['Tables']['table_name']['Row']</code> for complete rows, <code>Database['public']['Tables']['table_name']['Insert']</code> for insertions, and <code>Database['public']['Tables']['table_name']['Update']</code> for updates. See the Supabase TypeScript Type Generator for more details.</p> <p>By following this pattern, we ensure consistency across your full-stack application, whether you're working with TypeScript on the frontend or Python on the backend.</p>"},{"location":"examples/insert-update-models/#prerequisites-and-setup","title":"Prerequisites and Setup","text":"<p>You will need to follow the prerequisites listed in the original example.</p>"},{"location":"examples/insert-update-models/#new-generated-classes","title":"New Generated Classes","text":"<p>When you run the schema generation command (<code>sb-pydantic gen</code>), three model classes are generated for each table in your database:</p> <ol> <li> <p>Base (Row) Model (e.g., <code>ProductBaseSchema</code>/<code>Product</code>)</p> <ul> <li>Contains all fields with their proper types</li> <li>Used primarily for responses and full object representation</li> </ul> </li> <li> <p>Insert Model (e.g., <code>ProductInsert</code>)</p> <ul> <li>Includes only the fields required for creating new records</li> <li>Makes auto-generated or defaulted fields like <code>id</code> and <code>inserted_at</code> optional</li> <li>Required fields remain required, optional fields are still optional</li> </ul> </li> <li> <p>Update Model (e.g., <code>ProductUpdate</code>)</p> <ul> <li>Makes all fields optional since updates typically only modify a subset of fields</li> <li>Uses <code>Optional</code> types to ensure type safety when updating</li> </ul> </li> </ol>"},{"location":"examples/insert-update-models/#understanding-insert-and-update-models","title":"Understanding Insert and Update Models","text":"<p>When working with databases, the fields required for creating a new record (insertion) often differ from those needed to update an existing record. <code>supabase-pydantic</code> automatically generates specialized models for these operations:</p> <ul> <li>Insert Models: Include all required fields for creating new records</li> <li>Update Models: Make all fields optional since you typically only update specific fields</li> </ul>"},{"location":"examples/insert-update-models/#example-schema","title":"Example Schema","text":"<p>Let's look at a more comprehensive example using an e-commerce product catalog schema:</p> <pre><code>create type product_status as enum ('draft', 'active', 'archived');\ncreate type inventory_status as enum ('in_stock', 'low_stock', 'out_of_stock');\n\ncreate table products (\n    id uuid default gen_random_uuid() primary key,\n    sku text not null unique,\n    name text not null,\n    description text,\n    price decimal(10,2) not null,\n    category_id uuid references categories(id),\n    brand_id uuid references brands(id),\n    created_by uuid references auth.users,\n    created_at timestamp with time zone default timezone('utc'::text, now()),\n    updated_at timestamp with time zone default timezone('utc'::text, now()),\n    published_at timestamp with time zone,\n    status product_status default 'draft',\n    inventory_status inventory_status default 'out_of_stock',\n    stock_quantity integer default 0,\n    weight_grams integer,\n    dimensions jsonb default '{\"length\": 0, \"width\": 0, \"height\": 0}',\n    tags text[] default '{}',\n    attributes jsonb default '{}'\n);\n</code></pre>"},{"location":"examples/insert-update-models/#generated-models","title":"Generated Models","text":"<p>For the above schema, <code>supabase-pydantic</code> will generate three model classes with detailed field information (BaseSchema not included; see previous tutorial):</p> <pre><code>from datetime import datetime\nfrom typing import Optional, List\nfrom uuid import UUID4\nfrom decimal import Decimal\nfrom pydantic import BaseModel, Field, Json\n\n# ... other definitions ...\n\nclass ProductsInsert(CustomModelInsert):\n    \"\"\"Products Insert Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4 | None = Field(default=None)  # has default value\n\n    # Field properties:\n    # brand_id: nullable\n    # category_id: nullable\n    # created_at: has default value\n    # created_by: nullable\n    # description: nullable\n    # dimensions: has default value\n    # inventory_status: has default value\n    # published_at: nullable\n    # status: has default value\n    # stock_quantity: has default value\n    # tags: has default value\n    # weight_grams: nullable\n\n    # Required fields\n    sku: str\n    name: str\n    price: Decimal\n\n    # Optional fields\n    brand_id: UUID4 | None = Field(default=None)\n    category_id: UUID4 | None = Field(default=None)\n    created_at: datetime | None = Field(default=None)\n    created_by: UUID4 | None = Field(default=None)\n    description: str | None = Field(default=None)\n    dimensions: dict | list[dict] | list[Any] | Json | None = Field(default=None)\n    inventory_status: str | None = Field(default=None)\n    published_at: datetime | None = Field(default=None)\n    status: str | None = Field(default=None)\n    stock_quantity: int | None = Field(default=None)\n    tags: list[str] | None = Field(default=None)\n    weight_grams: int | None = Field(default=None)\n    attributes: dict | list[dict] | list[Any] | Json | None = Field(default=None)\n\n\nclass ProductsUpdate(CustomModelUpdate):\n    \"\"\"Products Update Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4 | None = Field(default=None)\n\n    # Field properties (same as Insert)\n    # brand_id: nullable\n    # category_id: nullable\n    # ...\n\n    # All fields are optional in Update model\n    brand_id: UUID4 | None = Field(default=None)\n    category_id: UUID4 | None = Field(default=None)\n    created_at: datetime | None = Field(default=None)\n    created_by: UUID4 | None = Field(default=None)\n    description: str | None = Field(default=None)\n    dimensions: dict | list[dict] | list[Any] | Json | None = Field(default=None)\n    inventory_status: str | None = Field(default=None)\n    name: str | None = Field(default=None)\n    price: Decimal | None = Field(default=None)\n    published_at: datetime | None = Field(default=None)\n    sku: str | None = Field(default=None)\n    status: str | None = Field(default=None)\n    stock_quantity: int | None = Field(default=None)\n    tags: List[str] | None = Field(default=None)\n    weight_grams: int | None = Field(default=None)\n    attributes: dict | list[dict] | list[Any] | Json | None = Field(default=None)\n</code></pre>"},{"location":"examples/insert-update-models/#key-features-illustrated","title":"Key Features Illustrated","text":"<ol> <li> <p>Smart Field Analysis:</p> <ul> <li>Required fields are preserved in the Insert model (<code>sku</code>, <code>name</code>, <code>price</code>)</li> <li>Fields with database defaults are optional (<code>id</code>, <code>created_at</code>, <code>stock_quantity</code>, etc.)</li> <li>Nullable fields (like <code>description</code>, <code>weight_grams</code>) are properly typed with <code>| None</code></li> </ul> </li> <li> <p>Advanced PostgreSQL Types:</p> <ul> <li>Enum types (<code>product_status</code>, <code>inventory_status</code>) are handled appropriately</li> <li>Array types (<code>tags text[]</code>) are mapped to <code>list[str]</code></li> <li>JSONB fields (<code>dimensions</code>, <code>attributes</code>) support both <code>dict</code> and <code>Json</code> types</li> <li>Decimal fields (<code>price</code>) use Python's <code>Decimal</code> for precision</li> </ul> </li> <li> <p>Field Property Documentation:</p> <ul> <li>Each model includes detailed comments about field properties</li> <li>Clearly indicates which fields are nullable or have default values</li> <li>Documents complex field relationships (foreign keys to <code>categories</code>, <code>brands</code>)</li> </ul> </li> <li> <p>Type Safety and Validation:</p> <ul> <li>Foreign keys use <code>UUID4</code> type for proper validation</li> <li>Complex types are properly mapped (<code>jsonb</code> \u2192 <code>dict | list[dict] | list[Any] | Json</code>, <code>text[]</code> \u2192 <code>list[str]</code>)</li> <li>All fields in Update model are optional with <code>| None</code></li> <li>Maintains type consistency with database constraints</li> </ul> </li> <li> <p>Default Value Handling:\\</p> <ul> <li>Smart handling of PostgreSQL defaults (<code>default gen_random_uuid()</code>, <code>default '{}'</code>)</li> <li>All optional fields use <code>Field(default=None)</code> for proper Pydantic validation</li> <li>Preserves database-level default values while ensuring type safety</li> </ul> </li> </ol>"},{"location":"examples/insert-update-models/#using-the-models","title":"Using the Models","text":"<p>Here's how to use these models in your FastAPI application:</p> <pre><code>from fastapi import FastAPI, HTTPException\nfrom supabase import create_client\nfrom uuid import UUID4\nfrom typing import list\n\napp = FastAPI()\nsupabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n\n@app.post(\"/products/\", response_model=Product)\nasync def create_product(product: ProductsInsert):\n    # Validate and insert new product\n    result = supabase.table(\"products\").insert(product.model_dump()).execute()\n    return result.data[0]\n\n@app.patch(\"/products/{product_id}\", response_model=Product)\nasync def update_product(product_id: UUID4, product: ProductsUpdate):\n    # Only send non-None values for update\n    update_data = {k: v for k, v in product.model_dump().items() if v is not None}\n    result = supabase.table(\"products\").update(update_data).eq(\"id\", product_id).execute()\n\n    if not result.data:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return result.data[0]\n\n@app.post(\"/products/{product_id}/stock\", response_model=Product)\nasync def update_stock(product_id: UUID4, quantity: int):\n    # Example of partial update using ProductsUpdate\n    update = ProductsUpdate(stock_quantity=quantity)\n    if quantity == 0:\n        update.inventory_status = \"out_of_stock\"\n    elif quantity &lt; 10:\n        update.inventory_status = \"low_stock\"\n    else:\n        update.inventory_status = \"in_stock\"\n\n    result = supabase.table(\"products\").update(update.model_dump(exclude_none=True)) \\\n        .eq(\"id\", product_id).execute()\n\n    if not result.data:\n        raise HTTPException(status_code=404, detail=\"Product not found\")\n    return result.data[0]\n</code></pre>"},{"location":"examples/insert-update-models/#key-features","title":"Key Features","text":"<ol> <li> <p>Smart Schema Handling:</p> <ul> <li>Insert models preserve required fields (<code>sku</code>, <code>name</code>, <code>price</code>)</li> <li>Update models make all fields optional for partial updates</li> <li>Proper handling of PostgreSQL types (enums, arrays, JSONB)</li> </ul> </li> <li> <p>Type Safety:</p> <ul> <li>Precise decimal handling for prices</li> <li>Proper UUID handling for IDs and foreign keys</li> <li>Array support for tags with <code>list[str]</code></li> <li>JSONB support for flexible attributes and dimensions</li> </ul> </li> <li> <p>Validation:</p> <ul> <li>Automatic validation of required fields</li> <li>Enum validation for product and inventory status</li> <li>Custom validators can be added for business logic</li> </ul> </li> </ol>"},{"location":"examples/insert-update-models/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use Specific Models for Specific Operations:</p> <ul> <li>Use <code>ProductsInsert</code> for creating new products</li> <li>Use <code>ProductsUpdate</code> for modifying existing products</li> <li>Use the base <code>Product</code> model for responses</li> <li>Create specific endpoints for common operations (like stock updates)</li> </ul> </li> <li> <p>Handle Complex Updates:</p> <ul> <li>Use <code>model_dump(exclude_none=True)</code> to only send changed fields</li> <li>Group related field updates (like stock quantity and status)</li> <li>Consider business logic when updating related fields</li> </ul> </li> <li> <p>Error Handling:</p> <ul> <li>Validate business rules before database operations</li> <li>Handle unique constraint violations (e.g., duplicate SKUs)</li> <li>Provide clear error messages for validation failures</li> </ul> </li> </ol>"},{"location":"examples/insert-update-models/#relationship-handling","title":"Relationship Handling","text":"<p>The models handle relationships with other tables appropriately:</p> <pre><code>class ProductWithRelations(Product):\n    # One-to-One relationship\n    primary_image: ProductImage | None\n\n    # One-to-Many relationships\n    variants: list[ProductVariant] | None\n    reviews: list[ProductReview] | None\n\n    # Many-to-Many relationships\n    categories: list[Category] | None\n    tags: list[Tag] | None\n</code></pre> <p>When working with relationships:</p> <ol> <li> <p>Foreign Keys:</p> <ul> <li><code>category_id</code> and <code>brand_id</code> are typed as <code>UUID4 | None</code></li> <li>Allows for optional relationships while maintaining type safety</li> </ul> </li> <li> <p>Nested Operations:</p> <ul> <li>Consider using separate endpoints for managing relationships</li> <li>Handle cascading updates carefully (e.g., updating all variants)</li> </ul> </li> <li> <p>Data Loading:</p> <ul> <li>Use <code>.select('*')</code> for basic queries</li> <li>Use <code>.select('*, categories(*)')</code> to include related data</li> </ul> </li> </ol>"},{"location":"examples/insert-update-models/#conclusion","title":"Conclusion","text":"<p>Using the generated Insert and Update models provides a type-safe and efficient way to handle database operations in your Supabase application. These models ensure that your API endpoints handle data correctly while maintaining proper validation and type checking.</p>"},{"location":"examples/model-prefix-example/","title":"Model Prefix Protection in Pydantic Models","text":"<p>This example demonstrates how to use the configurable model prefix protection feature in supabase-pydantic.</p>"},{"location":"examples/model-prefix-example/#background","title":"Background","text":"<p>Pydantic v2 reserves the \"model_\" prefix in its protected namespace, which means fields like <code>model_id</code>, <code>model_name</code>, or <code>model_version</code> would cause errors in Pydantic models. By default, supabase-pydantic renames such fields with a \"field_\" prefix (e.g., <code>field_model_id</code>) and adds the original name as an alias.</p> <p>This can cause issues in automated processes that expect field names to match database column names directly.</p>"},{"location":"examples/model-prefix-example/#setting-up-a-test-database","title":"Setting Up a Test Database","text":""},{"location":"examples/model-prefix-example/#create-database-objects","title":"Create Database Objects","text":"<p>Let's create a test database table with columns that have the \"model_\" prefix:</p> model_prefix_setup.sql<pre><code>-- Create test table with model_ prefixed columns\nCREATE TABLE model_test_items (\n    id SERIAL PRIMARY KEY,\n    name TEXT NOT NULL,\n    model_type TEXT,\n    model_version VARCHAR(50),\n    model_id UUID,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\n-- Insert some sample data\nINSERT INTO model_test_items (name, model_type, model_version, model_id) \nVALUES \n    ('Item 1', 'product', 'v1.0', gen_random_uuid()),\n    ('Item 2', 'service', 'v2.3.1', gen_random_uuid()),\n    ('Item 3', 'component', 'v0.9.5', gen_random_uuid());\n\n-- Create a view to demonstrate the feature with views\nCREATE VIEW model_test_items_view AS\nSELECT \n    id,\n    name,\n    model_type,\n    model_version,\n    model_id,\n    created_at,\n    updated_at\nFROM model_test_items;\n\n-- Grant necessary permissions if needed\n-- GRANT SELECT, INSERT, UPDATE, DELETE ON model_test_items TO your_user;\n-- GRANT SELECT ON model_test_items_view TO your_user;\n</code></pre> <p>To run this setup script:</p> Run setup script<pre><code>$ psql -d your_database -f model_prefix_setup.sql\n\nCREATE TABLE\nINSERT 0 3\nCREATE VIEW\n</code></pre>"},{"location":"examples/model-prefix-example/#default-behavior-protection-enabled","title":"Default Behavior (Protection Enabled)","text":"<p>By default, supabase-pydantic will protect against Pydantic's reserved \"model_\" prefix by renaming fields and using aliases:</p> Generate models with default protection<pre><code>$ supabase-pydantic gen --schema public --uri postgresql://user:password@localhost:5432/your_database\n\n2023-07-15 10:42:18 - INFO - PostGres connection is open.\n2023-07-15 10:42:19 - INFO - PostGres connection is closed.\n2023-07-15 10:42:19 - INFO - Generating models...\n2023-07-15 10:42:22 - INFO - Models generated successfully: /path/to/your/project/models.py\n2023-07-15 10:42:22 - INFO - File formatted successfully: /path/to/your/project/models.py\n</code></pre> <p>The generated model will include aliased fields:</p> Generated model with default protection<pre><code>class ModelTestItemsBaseSchema(CustomModel):\n    \"\"\"ModelTestItems Base Schema.\"\"\"\n\n    # Primary Keys\n    id: int\n\n    # Columns\n    created_at: datetime.datetime | None = Field(default=None)\n    field_model_id: UUID4 | None = Field(default=None, alias='model_id')\n    field_model_type: str | None = Field(default=None, alias='model_type')\n    field_model_version: str | None = Field(default=None, alias='model_version')\n    name: str\n    updated_at: datetime.datetime | None = Field(default=None)\n</code></pre>"},{"location":"examples/model-prefix-example/#disabling-model-prefix-protection","title":"Disabling Model Prefix Protection","text":"<p>To disable this protection and use the original column names directly in your models:</p> Generate models with protection disabled<pre><code>$ supabase-pydantic gen --schema public --uri postgresql://user:password@localhost:5432/your_database --disable-model-prefix-protection\n\n2023-07-15 10:43:45 - INFO - PostGres connection is open.\n2023-07-15 10:43:46 - INFO - PostGres connection is closed.\n2023-07-15 10:43:46 - INFO - Generating models...\n2023-07-15 10:43:48 - INFO - Models generated successfully: /path/to/your/project/models.py\n2023-07-15 10:43:48 - INFO - File formatted successfully: /path/to/your/project/models.py\n</code></pre> <p>This will generate models with direct \"model_\" prefixed fields:</p> Generated model with protection disabled<pre><code>class ModelTestItemsBaseSchema(CustomModel):\n    \"\"\"ModelTestItems Base Schema.\"\"\"\n\n    model_config = ConfigDict(protected_namespaces=())\n\n    # Primary Keys\n    id: int\n\n    # Columns\n    created_at: datetime.datetime | None = Field(default=None)\n    model_id: UUID4 | None = Field(default=None)\n    model_type: str | None = Field(default=None)\n    model_version: str | None = Field(default=None)\n    name: str\n    updated_at: datetime.datetime | None = Field(default=None)\n</code></pre>"},{"location":"examples/model-prefix-example/#usage-differences","title":"Usage Differences","text":""},{"location":"examples/model-prefix-example/#with-default-behavior","title":"With Default Behavior","text":"<p>When using the default models, you need to use the aliased field names:</p> Using models with default protection<pre><code>from models import ModelTestItemsBaseSchema\n\n# Creating an instance\nitem = ModelTestItemsBaseSchema(\n    id=1,\n    name=\"Test Item\",\n    field_model_type=\"product\",  # Use the prefixed field name\n    field_model_version=\"v1.0\",\n    field_model_id=\"123e4567-e89b-12d3-a456-426614174000\"\n)\n\n# But when serializing to JSON, the original column names are used\nprint(item.model_dump(by_alias=True))\n# {'id': 1, 'name': 'Test Item', 'model_type': 'product', 'model_version': 'v1.0', 'model_id': '123e4567-e89b-12d3-a456-426614174000', ...}\n</code></pre>"},{"location":"examples/model-prefix-example/#with-protection-disabled","title":"With Protection Disabled","text":"<p>With protection disabled, you can use the original column names directly:</p> Using models with protection disabled<pre><code>from models import ModelTestItemsBaseSchema\n\n# Creating an instance\nitem = ModelTestItemsBaseSchema(\n    id=1,\n    name=\"Test Item\",\n    model_type=\"product\",  # Use the original column name\n    model_version=\"v1.0\",\n    model_id=\"123e4567-e89b-12d3-a456-426614174000\"\n)\n\n# Serializing to JSON uses the same names\nprint(item.model_dump())\n# {'id': 1, 'name': 'Test Item', 'model_type': 'product', 'model_version': 'v1.0', 'model_id': '123e4567-e89b-12d3-a456-426614174000', ...}\n</code></pre>"},{"location":"examples/model-prefix-example/#when-to-use-this-option","title":"When to Use This Option","text":"<p>Consider using this option when:</p> <ul> <li>You are working with machine learning models where fields like <code>model_id</code>, <code>model_version</code>, and <code>model_type</code> are common and meaningful</li> <li>You're building data science applications that need to track model lineage, versioning, and metadata</li> <li>You have automated processes that need field names to match database column names exactly</li> <li>You're using tools that don't handle aliases well</li> <li>You need to serialize/deserialize models with original field names</li> <li>You're integrating with external systems that expect specific field names</li> </ul> <p>Keep the default behavior when:</p> <ul> <li>You want to adhere to Pydantic's recommended practices</li> <li>You need maximum compatibility with various Pydantic versions</li> <li>Your field naming can be flexible</li> </ul>"},{"location":"examples/model-prefix-example/#clean-up","title":"Clean Up","text":""},{"location":"examples/model-prefix-example/#remove-test-database-objects","title":"Remove Test Database Objects","text":"<p>When done testing, you can clean up your database:</p> model_prefix_cleanup.sql<pre><code>-- Cleanup script for testing model prefix protection feature\n\n-- Drop the view first\nDROP VIEW IF EXISTS model_test_items_view;\n\n-- Drop the table and all dependent objects\nDROP TABLE IF EXISTS model_test_items CASCADE;\n\n-- If you created any additional objects, drop them here\n-- DROP TYPE IF EXISTS your_custom_type;\n-- DROP FUNCTION IF EXISTS your_custom_function();\n</code></pre> <p>To run this cleanup script:</p> Run cleanup script<pre><code>$ psql -d your_database -f model_prefix_cleanup.sql\n\nDROP VIEW\nDROP TABLE\n</code></pre>"},{"location":"examples/model-prefix-example/#references","title":"References","text":"<p>These resources provide more information about Pydantic's protected namespaces feature and the reasoning behind it:</p> <ul> <li>Pydantic Documentation: Protected Namespaces - Official documentation explaining Pydantic's protected namespaces feature and how to configure them.</li> <li>Pydantic GitHub Issue #9427 - Discussion about the model_ prefix protection in Pydantic v2 and its impact on users migrating from v1.</li> </ul>"},{"location":"examples/mysql-support/","title":"Working with MySQL Databases","text":"<p>This guide demonstrates how to use <code>supabase-pydantic</code> with MySQL databases. As of September 2025, the tool now fully supports generating Pydantic and SQLAlchemy models directly from MySQL databases.</p> <p>Please note ...</p> <p>MySQL support is a stable feature. If you encounter any issues specific to MySQL database connections, please report them.</p>"},{"location":"examples/mysql-support/#prerequisites","title":"Prerequisites","text":"<p>You will need to have:</p> <ul> <li>Python 3.10 or higher</li> <li>A MySQL database</li> <li>The <code>supabase-pydantic</code> package installed</li> </ul>"},{"location":"examples/mysql-support/#connecting-to-mysql","title":"Connecting to MySQL","text":"<p>To generate models from a MySQL database, use the <code>--db-type mysql</code> flag with your connection:</p> Connect to Remote MySQL Database<pre><code>$ sb-pydantic gen --type pydantic --framework fastapi --db-type mysql --db-url mysql://username:password@hostname:3306/database_name\n\n2023-09-12 14:30:15 - INFO - MySQL connection opened successfully\n2023-09-12 14:30:17 - INFO - Processing database: database_name\n2023-09-12 14:30:19 - INFO - MySQL connection closed successfully\n2023-09-12 14:30:20 - INFO - Generating FastAPI Pydantic models...\n2023-09-12 14:30:22 - INFO - FastAPI Pydantic models generated successfully: /path/to/your/project/entities/fastapi/schemas_latest.py\n2023-09-12 14:30:23 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schemas_latest.py\n</code></pre> <p>Or with a local database:</p> Connect to Local MySQL Database<pre><code>$ sb-pydantic gen --type pydantic --framework fastapi --db-type mysql --db-url mysql://root:password@localhost:3306/mydb\n\n2023-09-12 14:30:15 - INFO - MySQL connection opened successfully\n2023-09-12 14:30:17 - INFO - Processing database: mydb\n2023-09-12 14:30:19 - INFO - MySQL connection closed successfully\n2023-09-12 14:30:20 - INFO - Generating FastAPI Pydantic models...\n2023-09-12 14:30:22 - INFO - FastAPI Pydantic models generated successfully: /path/to/your/project/entities/fastapi/schemas_latest.py\n2023-09-12 14:30:23 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schemas_latest.py\n</code></pre>"},{"location":"examples/mysql-support/#generating-different-model-types","title":"Generating Different Model Types","text":""},{"location":"examples/mysql-support/#pydantic-models","title":"Pydantic Models","text":"<p>Generate Pydantic models from a MySQL database:</p> Generate Pydantic Models<pre><code>$ sb-pydantic gen --type pydantic --framework fastapi --db-type mysql --db-url mysql://username:password@hostname:3306/database_name\n</code></pre>"},{"location":"examples/mysql-support/#sqlalchemy-models","title":"SQLAlchemy Models","text":"<p>Generate SQLAlchemy ORM models from a MySQL database:</p> Generate SQLAlchemy Models<pre><code>$ sb-pydantic gen --type sqlalchemy --db-type mysql --db-url mysql://username:password@hostname:3306/database_name\n\n2023-09-12 14:30:15 - INFO - MySQL connection opened successfully\n2023-09-12 14:30:17 - INFO - Processing database: database_name\n2023-09-12 14:30:19 - INFO - MySQL connection closed successfully\n2023-09-12 14:30:20 - INFO - Generating SQLAlchemy models...\n2023-09-12 14:30:22 - INFO - SQLAlchemy models generated successfully: /path/to/your/project/entities/sqlalchemy_latest.py\n2023-09-12 14:30:23 - INFO - File formatted successfully: /path/to/your/project/entities/sqlalchemy_latest.py\n</code></pre>"},{"location":"examples/mysql-support/#customizing-output","title":"Customizing Output","text":"<p>You can customize the output directory and specify schemas:</p> Customize Output Directory and Schema<pre><code>$ sb-pydantic gen --type pydantic --framework fastapi --db-type mysql --db-url mysql://username:password@hostname:3306/database_name --dir ./my_models --schema main\n\n2023-09-12 14:30:15 - INFO - MySQL connection opened successfully\n2023-09-12 14:30:17 - INFO - Processing schema: main\n2023-09-12 14:30:19 - INFO - MySQL connection closed successfully\n2023-09-12 14:30:20 - INFO - Generating FastAPI Pydantic models...\n2023-09-12 14:30:22 - INFO - FastAPI Pydantic models generated successfully: /path/to/your/project/my_models/fastapi/schemas_latest.py\n2023-09-12 14:30:23 - INFO - File formatted successfully: /path/to/your/project/my_models/fastapi/schemas_latest.py\n</code></pre>"},{"location":"examples/mysql-support/#troubleshooting","title":"Troubleshooting","text":""},{"location":"examples/mysql-support/#type-mapping-errors","title":"Type Mapping Errors","text":"<p>If you encounter issues with specific MySQL data types not mapping correctly:</p> Verbose Mode<pre><code>$ sb-pydantic gen --type pydantic --framework fastapi --db-type mysql --db-url mysql://username:password@hostname:3306/database_name --debug\n</code></pre> <p>Debug mode will show more details about the type mapping process, helping you identify any issues.</p>"},{"location":"examples/mysql-support/#support-for-mysql-constraints","title":"Support for MySQL Constraints","text":"<p>The following MySQL constraints are properly detected and mapped to your models:</p> <ul> <li>Primary keys (converted to primary key fields)</li> <li>Foreign keys (converted to relationship fields)</li> <li>Unique constraints (annotated with <code>@Field(unique=True)</code>)</li> <li>Default values (provided as field defaults)</li> <li>NOT NULL constraints (reflected in model typing)</li> </ul>"},{"location":"examples/mysql-support/#example-output","title":"Example Output","text":"<p>Here's a simplified example of the generated Pydantic model:</p> Generated Pydantic Model Example<pre><code># Generated by supabase-pydantic 0.4.0\n# Do not modify this file manually\n\nfrom datetime import date, datetime\nfrom decimal import Decimal\nfrom typing import List, Optional\n\nfrom pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    id: int = Field(primary_key=True)\n    username: str = Field(max_length=50, unique=True)\n    email: str = Field(max_length=100, unique=True)\n    password_hash: str = Field(max_length=255)\n    created_at: datetime\n    updated_at: Optional[datetime] = None\n    is_active: bool = True\n\n\nclass Post(BaseModel):\n    id: int = Field(primary_key=True)\n    title: str = Field(max_length=100)\n    content: str\n    user_id: int = Field(foreign_key=\"user.id\")\n    published_date: date\n    views: Optional[int] = 0\n    user: Optional[User] = None\n</code></pre> <p>And here's a simplified example of the generated SQLAlchemy model:</p> Generated SQLAlchemy Model Example<pre><code># Generated by supabase-pydantic 0.4.0\n# Do not modify this file manually\n\nfrom datetime import date, datetime\nfrom decimal import Decimal\nfrom typing import Optional\n\nfrom sqlalchemy import Boolean, Column, Date, DateTime, ForeignKey, Integer, String, Text\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship\n\nBase = declarative_base()\n\n\nclass User(Base):\n    __tablename__ = \"user\"\n\n    id = Column(Integer, primary_key=True)\n    username = Column(String(50), unique=True, nullable=False)\n    email = Column(String(100), unique=True, nullable=False)\n    password_hash = Column(String(255), nullable=False)\n    created_at = Column(DateTime, nullable=False)\n    updated_at = Column(DateTime)\n    is_active = Column(Boolean, default=True)\n\n    posts = relationship(\"Post\", back_populates=\"user\")\n\n\nclass Post(Base):\n    __tablename__ = \"post\"\n\n    id = Column(Integer, primary_key=True)\n    title = Column(String(100), nullable=False)\n    content = Column(Text, nullable=False)\n    user_id = Column(Integer, ForeignKey(\"user.id\"), nullable=False)\n    published_date = Column(Date, nullable=False)\n    views = Column(Integer, default=0)\n\n    user = relationship(\"User\", back_populates=\"posts\")\n</code></pre>"},{"location":"examples/mysql-support/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Connection Security: Use environment variables for your database credentials instead of hardcoding them</p> </li> <li> <p>Schema Selection: Be specific about which schemas to include with <code>--schema</code> to improve generation speed</p> </li> <li> <p>Data Types: Review the generated models to ensure MySQL-specific types are correctly mapped</p> </li> <li> <p>Relationships: Test relationship navigation in the generated models to confirm proper setup</p> </li> <li> <p>Versioning: Keep track of model versions when regenerating after database changes</p> </li> </ol>"},{"location":"examples/mysql-support/#conclusion","title":"Conclusion","text":"<p>With MySQL support, <code>supabase-pydantic</code> now offers greater flexibility for developers working with different database systems. You can seamlessly generate type-safe models from your MySQL database and integrate them with FastAPI or other Python frameworks.</p> <p>Whether you're working with PostgreSQL, Supabase, or MySQL, the workflow remains consistent, allowing you to focus on building your application rather than writing boilerplate code. Report any issues you encounter in our GitHub repository.</p>"},{"location":"examples/setup-slack-simple-fastapi/","title":"Generating FastAPI Schemas from the Slack Clone","text":"<p>This example is a simple demonstration of how to generate FastAPI schemas from the Slack clone database tutorial provided by Supabase. </p> <p>New Feature - Insert and Update Models (Feb 16, 2025)</p> <p>The generated models now include specialized Insert and Update models for better type safety and validation. See the Working with Insert and Update Models guide for details.</p>"},{"location":"examples/setup-slack-simple-fastapi/#prerequisites","title":"Prerequisites","text":"<p>You will need to have the following installed:</p> <ul> <li>Python 3.10 or higher and whatever environment and package manager you prefer (e.g. <code>pipenv</code>, <code>poetry</code>, <code>conda</code>, <code>venv</code>, etc.)</li> <li>The Supabase CLI</li> <li>This package </li> </ul>"},{"location":"examples/setup-slack-simple-fastapi/#setup","title":"Setup","text":"<p>Start a new supabase instance locally using the supabase cli (see the Supabase CLI documentation for more information):</p> <pre><code>mkdir slack-clone\ncd slack-clone\nsupabase init\n# ... the cli will run through a setup process. \n# ... after it finishes successfully, run the following command to start the project\nsupabase start\n</code></pre> <p>Navigate to the local Studio URL (usually <code>http://127.0.0.1:54323</code>) and go to the SQL Editor. There, click the \"Quickstarts\" option and choose the \"Slack Clone\" quickstart. This will open an editor to create the necessary tables and sample data for the Slack clone. For completeness, the SQL code used in this example is provided here:</p> Slack Clone SQL Code <pre><code>-- For use with https://github.com/supabase/supabase/tree/master/examples/slack-clone/nextjs-slack-clone\n\n-- Custom types\ncreate type public.app_permission as enum ('channels.delete', 'messages.delete');\ncreate type public.app_role as enum ('admin', 'moderator');\ncreate type public.user_status as enum ('ONLINE', 'OFFLINE');\n\n-- USERS\ncreate table public.users (\n  id          uuid not null primary key, -- UUID from auth.users\n  username    text,\n  status      user_status default 'OFFLINE'::public.user_status\n);\ncomment on table public.users is 'Profile data for each user.';\ncomment on column public.users.id is 'References the internal Supabase Auth user.';\n\n-- CHANNELS\ncreate table public.channels (\n  id            bigint generated by default as identity primary key,\n  inserted_at   timestamp with time zone default timezone('utc'::text, now()) not null,\n  slug          text not null unique,\n  created_by    uuid references public.users not null\n);\ncomment on table public.channels is 'Topics and groups.';\n\n-- MESSAGES\ncreate table public.messages (\n  id            bigint generated by default as identity primary key,\n  inserted_at   timestamp with time zone default timezone('utc'::text, now()) not null,\n  message       text,\n  user_id       uuid references public.users not null,\n  channel_id    bigint references public.channels on delete cascade not null\n);\ncomment on table public.messages is 'Individual messages sent by each user.';\n\n-- USER ROLES\ncreate table public.user_roles (\n  id        bigint generated by default as identity primary key,\n  user_id   uuid references public.users on delete cascade not null,\n  role      app_role not null,\n  unique (user_id, role)\n);\ncomment on table public.user_roles is 'Application roles for each user.';\n\n-- ROLE PERMISSIONS\ncreate table public.role_permissions (\n  id           bigint generated by default as identity primary key,\n  role         app_role not null,\n  permission   app_permission not null,\n  unique (role, permission)\n);\ncomment on table public.role_permissions is 'Application permissions for each role.';\n\n-- authorize with role-based access control (RBAC)\ncreate function public.authorize(\n  requested_permission app_permission,\n  user_id uuid\n)\nreturns boolean as\n$$\n  declare\n    bind_permissions int;\n  begin\n    select\n      count(*)\n    from public.role_permissions\n    inner join public.user_roles on role_permissions.role = user_roles.role\n    where\n      role_permissions.permission = authorize.requested_permission and\n      user_roles.user_id = authorize.user_id\n    into bind_permissions;\n\n    return bind_permissions &gt; 0;\n  end;\n$$\nlanguage plpgsql security definer;\n\n-- Secure the tables\nalter table public.users\n  enable row level security;\nalter table public.channels\n  enable row level security;\nalter table public.messages\n  enable row level security;\nalter table public.user_roles\n  enable row level security;\nalter table public.role_permissions\n  enable row level security;\n\ncreate policy \"Allow logged-in read access\" on public.users\n  for select using (auth.role() = 'authenticated');\ncreate policy \"Allow individual insert access\" on public.users\n  for insert with check ((select auth.uid()) = id);\ncreate policy \"Allow individual update access\" on public.users\n  for update using ( (select auth.uid()) = id );\ncreate policy \"Allow logged-in read access\" on public.channels\n  for select using (auth.role() = 'authenticated');\ncreate policy \"Allow individual insert access\" on public.channels\n  for insert with check ((select auth.uid()) = created_by);\ncreate policy \"Allow individual delete access\" on public.channels\n  for delete using ((select auth.uid()) = created_by);\ncreate policy \"Allow authorized delete access\" on public.channels\n  for delete using (authorize('channels.delete', auth.uid()));\ncreate policy \"Allow logged-in read access\" on public.messages\n  for select using (auth.role() = 'authenticated');\ncreate policy \"Allow individual insert access\" on public.messages\n  for insert with check ((select auth.uid()) = user_id);\ncreate policy \"Allow individual update access\" on public.messages\n  for update using ((select auth.uid()) = user_id);\ncreate policy \"Allow individual delete access\" on public.messages\n  for delete using ((select auth.uid()) = user_id);\ncreate policy \"Allow authorized delete access\" on public.messages\n  for delete using (authorize('messages.delete', auth.uid()));\ncreate policy \"Allow individual read access\" on public.user_roles\n  for select using ((select auth.uid()) = user_id);\n\n-- Send \"previous data\" on change\nalter table public.users\n  replica identity full;\nalter table public.channels\n  replica identity full;\nalter table public.messages\n  replica identity full;\n\n-- inserts a row into public.users and assigns roles\ncreate function public.handle_new_user()\nreturns trigger as\n$$\n  declare is_admin boolean;\n  begin\n    insert into public.users (id, username)\n    values (new.id, new.email);\n\n    select count(*) = 1 from auth.users into is_admin;\n\n    if position('+supaadmin@' in new.email) &gt; 0 then\n      insert into public.user_roles (user_id, role) values (new.id, 'admin');\n    elsif position('+supamod@' in new.email) &gt; 0 then\n      insert into public.user_roles (user_id, role) values (new.id, 'moderator');\n    end if;\n\n    return new;\n  end;\n$$ language plpgsql security definer;\n\n-- trigger the function every time a user is created\ncreate trigger on_auth_user_created\n  after insert on auth.users\n  for each row execute procedure public.handle_new_user();\n\n/**\n* REALTIME SUBSCRIPTIONS\n* Only allow realtime listening on public tables.\n*/\n\nbegin;\n  -- remove the realtime publication\n  drop publication if exists supabase_realtime;\n\n  -- re-create the publication but don't enable it for any tables\n  create publication supabase_realtime;\ncommit;\n\n-- add tables to the publication\nalter publication supabase_realtime add table public.channels;\nalter publication supabase_realtime add table public.messages;\nalter publication supabase_realtime add table public.users;\n\n-- DUMMY DATA\ninsert into public.users (id, username)\nvalues\n    ('8d0fd2b3-9ca7-4d9e-a95f-9e13dded323e', 'supabot');\n\ninsert into public.channels (slug, created_by)\nvalues\n    ('public', '8d0fd2b3-9ca7-4d9e-a95f-9e13dded323e'),\n    ('random', '8d0fd2b3-9ca7-4d9e-a95f-9e13dded323e');\n\ninsert into public.messages (message, channel_id, user_id)\nvalues\n    ('Hello World \ud83d\udc4b', 1, '8d0fd2b3-9ca7-4d9e-a95f-9e13dded323e'),\n    ('Perfection is attained, not when there is nothing more to add, but when there is nothing left to take away.', 2, '8d0fd2b3-9ca7-4d9e-a95f-9e13dded323e');\n\ninsert into public.role_permissions (role, permission)\nvalues\n    ('admin', 'channels.delete'),\n    ('admin', 'messages.delete'),\n    ('moderator', 'messages.delete');\n</code></pre> <p> Keep your local Supabase instance running. </p>"},{"location":"examples/setup-slack-simple-fastapi/#generating-schemas","title":"Generating Schemas","text":"<p>What makes the <code>supabase-pydantic</code> package so powerful is its ability to translate schema changes quickly, while developing your data layer, into Pydantic schemas. To do this, you will need to install the package in any project, then run the <code>generate</code> command:</p> Generate Schemas<pre><code>$ cd /path/to/your/project  # ... then activate your environment\n$ pip install supabase-pydantic\n$ sb-pydantic gen --type pydantic --framework fastapi --local\n\n2023-07-15 10:15:32 - INFO - PostGres connection is open.\n2023-07-15 10:15:33 - INFO - PostGres connection is closed.\n2023-07-15 10:15:33 - INFO - Generating FastAPI Pydantic models...\n2023-07-15 10:15:35 - INFO - FastAPI Pydantic models generated successfully: /path/to/your/project/entities/fastapi/schemas_latest.py\n2023-07-15 10:15:35 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schemas_latest.py\n</code></pre> <p>... and that's it. You now have a <code>schemas.py</code> file in your project that contains the Pydantic models for the Slack database:</p> schemas.py<pre><code>from __future__ import annotations\n\nfrom datetime import datetime\n\nfrom pydantic import UUID4, BaseModel, Field\n\n############################## Custom Classes\n# Note: This is a custom model class for defining common features among\n# Pydantic Base Schema.\n\n\nclass CustomModel(BaseModel):\n    pass\n\n\n############################## Base Classes\n\n\nclass ChannelsBaseSchema(CustomModel):\n    \"\"\"Channels Base Schema.\"\"\"\n\n    # Primary Keys\n    id: int\n\n    # Columns\n    created_by: UUID4\n    inserted_at: datetime\n    slug: str\n\n\nclass MessagesBaseSchema(CustomModel):\n    \"\"\"Messages Base Schema.\"\"\"\n\n    # Primary Keys\n    id: int\n\n    # Columns\n    channel_id: int\n    inserted_at: datetime\n    message: str | None = Field(default=None)\n    user_id: UUID4\n\n\nclass RolePermissionsBaseSchema(CustomModel):\n    \"\"\"RolePermissions Base Schema.\"\"\"\n\n    # Primary Keys\n    id: int\n\n    # Columns\n    permission: str\n    role: str\n\n\nclass UserRolesBaseSchema(CustomModel):\n    \"\"\"UserRoles Base Schema.\"\"\"\n\n    # Primary Keys\n    id: int\n\n    # Columns\n    role: str\n    user_id: UUID4\n\n\nclass UsersBaseSchema(CustomModel):\n    \"\"\"Users Base Schema.\"\"\"\n\n    # Primary Keys\n    id: UUID4\n\n    # Columns\n    status: str | None = Field(default=None)\n    username: str | None = Field(default=None)\n\n\n############################## Operational Classes\n\n\nclass Channels(ChannelsBaseSchema):\n    \"\"\"Channels Schema for Pydantic.\n\n    Inherits from ChannelsBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    users: list[Users] | None = Field(default=None)\n    messages: list[Messages] | None = Field(default=None)\n\n\nclass Messages(MessagesBaseSchema):\n    \"\"\"Messages Schema for Pydantic.\n\n    Inherits from MessagesBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    channels: list[Channels] | None = Field(default=None)\n    users: list[Users] | None = Field(default=None)\n\n\nclass RolePermissions(RolePermissionsBaseSchema):\n    \"\"\"RolePermissions Schema for Pydantic.\n\n    Inherits from RolePermissionsBaseSchema. Add any customization here.\n    \"\"\"\n\n    pass\n\n\nclass UserRoles(UserRolesBaseSchema):\n    \"\"\"UserRoles Schema for Pydantic.\n\n    Inherits from UserRolesBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    users: list[Users] | None = Field(default=None)\n\n\nclass Users(UsersBaseSchema):\n    \"\"\"Users Schema for Pydantic.\n\n    Inherits from UsersBaseSchema. Add any customization here.\n    \"\"\"\n\n    # Foreign Keys\n    channels: list[Channels] | None = Field(default=None)\n    messages: list[Messages] | None = Field(default=None)\n    user_roles: list[UserRoles] | None = Field(default=None)\n</code></pre>"},{"location":"examples/setup-slack-simple-fastapi/#exploring-the-schemas","title":"Exploring the Schemas","text":"<p>The generated schemas are based on the tables and relationships defined in the Slack clone database. The <code>BaseSchema</code> classes represent the base structure of each table, while the <code>Operational</code> classes represent the operational schema that can be used in your FastAPI application. Use these schemas to interact with the database and build your FastAPI application.</p> <p>Please note some of the following features which will be created in future releases:</p> <ul> <li>Generate all-null parent or base schemas for data manipulation in progeny BaseModels</li> <li>Create models for different ORM libraries (e.g. SQLAlchemy, Tortoise-ORM, etc.)</li> <li>Automatically generate CRUD operations for FastAPI applications and other frameworks</li> <li>Configuration options to prune and choose which tables to generate schemas for</li> <li>Support for more complex database structures and relationships</li> <li>Additional API related security measures and standard ORM methods</li> </ul>"},{"location":"examples/setup-slack-simple-fastapi/#conclusion","title":"Conclusion","text":"<p>This example demonstrates how to generate FastAPI schemas from the Slack clone database using the <code>supabase-pydantic</code> package. By following the steps outlined in this example, you can quickly generate Pydantic schemas for your FastAPI application and start building your data layer in an automated and efficient manner.</p> <p></p>"},{"location":"examples/singular-class-names/","title":"Singular Class Names","text":"<p>By default, supabase-pydantic generates class names that directly mirror your table names. For tables with plural names like <code>products</code>, <code>users</code>, or <code>categories</code>, this results in class names like <code>Products</code>, <code>Users</code>, and <code>Categories</code>.</p> <p>However, following object-oriented programming best practices, many developers prefer singular class names that represent individual entities. A <code>Product</code> class represents a single product, not multiple products.</p> <p>The <code>--singular-names</code> flag addresses this preference by automatically converting plural table names to singular class names.</p>"},{"location":"examples/singular-class-names/#understanding-the-generated-class-structure","title":"Understanding the Generated Class Structure","text":"<p>supabase-pydantic generates two types of classes for each table:</p> <ol> <li>Base Schema Classes (e.g., <code>ProductBaseSchema</code>): Parent classes containing only the direct table column definitions</li> <li>Main Model Classes (e.g., <code>Product</code>): The classes you actually use in your code, which inherit from the base schemas and include relationship fields</li> </ol> <p>The <code>--singular-names</code> flag affects both the base schema names and the main model class names.</p>"},{"location":"examples/singular-class-names/#basic-usage","title":"Basic Usage","text":""},{"location":"examples/singular-class-names/#default-behavior-plural-class-names","title":"Default Behavior (Plural Class Names)","text":"<pre><code>supabase-pydantic gen --db-url \"postgresql://user:pass@localhost/mydb\"\n</code></pre> <p>For a table named <code>products</code>, this generates:</p> <pre><code># Base schema (parent class)\nclass ProductsBaseSchema(BaseModel):\n    id: int\n    name: str\n    price: Decimal\n    # ... other fields\n\n# Main model class (inherits from base schema)\nclass Products(ProductsBaseSchema):\n    pass\n\n# CRUD model variants\nclass ProductsInsert(BaseModelInsert):\n    name: str\n    price: Decimal\n    # ... other fields\n\nclass ProductsUpdate(BaseModelUpdate):\n    name: str | None = None\n    price: Decimal | None = None\n    # ... other fields\n</code></pre>"},{"location":"examples/singular-class-names/#with-singular-class-names","title":"With Singular Class Names","text":"<pre><code>supabase-pydantic gen --db-url \"postgresql://user:pass@localhost/mydb\" --singular-names\n</code></pre> <p>For the same <code>products</code> table, this generates:</p> <pre><code># Base schema (parent class) - now singular\nclass ProductBaseSchema(BaseModel):  # Note: \"Product\" not \"Products\"\n    id: int\n    name: str\n    price: Decimal\n    # ... other fields\n\n# Main model class (inherits from base schema) - singular\nclass Product(ProductBaseSchema):  # Note: \"Product\" not \"Products\"\n    pass\n\n# CRUD model variants - also singular\nclass ProductInsert(BaseModelInsert):\n    name: str\n    price: Decimal\n    # ... other fields\n\nclass ProductUpdate(BaseModelUpdate):\n    name: str | None = None\n    price: Decimal | None = None\n    # ... other fields\n</code></pre>"},{"location":"examples/singular-class-names/#examples","title":"Examples","text":""},{"location":"examples/singular-class-names/#common-table-name-transformations","title":"Common Table Name Transformations","text":"Table Name Default Class Name With <code>--singular-names</code> <code>products</code> <code>Products</code> <code>Product</code> <code>users</code> <code>Users</code> <code>User</code> <code>categories</code> <code>Categories</code> <code>Category</code> <code>companies</code> <code>Companies</code> <code>Company</code> <code>addresses</code> <code>Addresses</code> <code>Address</code> <code>order_items</code> <code>OrderItems</code> <code>OrderItem</code> <code>user_profiles</code> <code>UserProfiles</code> <code>UserProfile</code>"},{"location":"examples/singular-class-names/#complete-example","title":"Complete Example","text":"<p>Let's say you have a database with these tables: - <code>users</code> - <code>products</code>  - <code>orders</code> - <code>order_items</code></p>"},{"location":"examples/singular-class-names/#without-singular-names","title":"Without <code>--singular-names</code>:","text":"<pre><code># Base schemas (parent classes)\nclass UsersBaseSchema(BaseModel):\n    id: int\n    email: str\n    name: str\n\nclass ProductsBaseSchema(BaseModel):\n    id: int\n    name: str\n    price: Decimal\n\nclass OrdersBaseSchema(BaseModel):\n    id: int\n    user_id: int\n    total: Decimal\n\nclass OrderItemsBaseSchema(BaseModel):\n    id: int\n    order_id: int\n    product_id: int\n    quantity: int\n\n# Main model classes (inherit from base schemas)\nclass Users(UsersBaseSchema):\n    pass\n\nclass Products(ProductsBaseSchema):\n    pass\n\nclass Orders(OrdersBaseSchema):\n    pass\n\nclass OrderItems(OrderItemsBaseSchema):\n    pass\n</code></pre>"},{"location":"examples/singular-class-names/#with-singular-names","title":"With <code>--singular-names</code>:","text":"<pre><code># Base schemas (parent classes) - now singular\nclass UserBaseSchema(BaseModel):\n    id: int\n    email: str\n    name: str\n\nclass ProductBaseSchema(BaseModel):\n    id: int\n    name: str\n    price: Decimal\n\nclass OrderBaseSchema(BaseModel):\n    id: int\n    user_id: int\n    total: Decimal\n\nclass OrderItemBaseSchema(BaseModel):\n    id: int\n    order_id: int\n    product_id: int\n    quantity: int\n\n# Main model classes (inherit from base schemas) - singular\nclass User(UserBaseSchema):\n    pass\n\nclass Product(ProductBaseSchema):\n    pass\n\nclass Order(OrderBaseSchema):\n    pass\n\nclass OrderItem(OrderItemBaseSchema):\n    pass\n</code></pre>"},{"location":"examples/singular-class-names/#when-to-use-singular-names","title":"When to Use Singular Names","text":""},{"location":"examples/singular-class-names/#recommended-use-cases","title":"\u2705 Recommended Use Cases","text":"<ul> <li>Following OOP best practices: Individual class instances represent single entities</li> <li>API development: RESTful APIs typically use singular nouns for resource models</li> <li>Code readability: <code>user = User()</code> reads more naturally than <code>user = Users()</code></li> <li>Framework conventions: Many ORMs and frameworks expect singular model names</li> <li>Team standards: When your team prefers singular class names</li> </ul>"},{"location":"examples/singular-class-names/#consider-carefully","title":"\u26a0\ufe0f Consider Carefully","text":"<ul> <li>Existing codebases: Changing from plural to singular names is a breaking change</li> <li>Database naming conventions: If your database uses singular table names, you may not need this flag</li> <li>Mixed naming: If some tables are singular and others plural, results may be inconsistent</li> </ul>"},{"location":"examples/singular-class-names/#important-notes","title":"Important Notes","text":""},{"location":"examples/singular-class-names/#what-gets-singularized","title":"What Gets Singularized","text":"<p>The <code>--singular-names</code> flag only affects class names. It does not change:</p> <ul> <li>\u274c Table names: Still references the actual <code>products</code> table</li> <li>\u274c Column names: Field names remain unchanged</li> <li>\u274c Relationship field names: Foreign key relationships use appropriate pluralization</li> </ul>"},{"location":"examples/singular-class-names/#relationship-handling","title":"Relationship Handling","text":"<p>The singularization is intelligent about relationships and follows semantic conventions for relationship field names:</p> <pre><code># With --singular-names enabled - Base schemas (parent classes, table columns only)\nclass UserBaseSchema(BaseModel):\n    id: int\n    email: str\n\nclass OrderBaseSchema(BaseModel):\n    id: int\n    user_id: int\n\n# Main model classes (inherit from base schemas, include relationships)\nclass User(UserBaseSchema):\n    # One-to-many relationship: user has many orders (plural)\n    orders: list[Order] | None = Field(default=None)\n\nclass Order(OrderBaseSchema):\n    # Many-to-one relationship: order belongs to one user (singular)\n    user: User | None = Field(default=None)\n</code></pre>"},{"location":"examples/singular-class-names/#semantic-pluralization-rules-for-relationships","title":"Semantic Pluralization Rules for Relationships","text":"<p>The <code>--singular-names</code> flag only affects class names, not relationship field names. Relationship fields follow semantic grammar rules based on the relationship type:</p> Relationship Type Field Name Convention Example Reasoning One-to-One Singular <code>user.profile</code> One user has one profile One-to-Many Plural <code>user.orders</code> One user has many orders Many-to-One Singular <code>order.user</code> Many orders belong to one user Many-to-Many Plural <code>post.tags</code> One post has many tags"},{"location":"examples/singular-class-names/#detailed-examples","title":"Detailed Examples","text":"<p>Consider a database with <code>users</code>, <code>orders</code>, <code>products</code>, and <code>order_items</code> tables:</p> <pre><code># Generated with --singular-names - Base schemas (parent classes, table columns only)\nclass UserBaseSchema(BaseModel):\n    id: int\n    email: str\n    name: str\n\nclass OrderBaseSchema(BaseModel):\n    id: int\n    user_id: int\n    total: Decimal\n\nclass ProductBaseSchema(BaseModel):\n    id: int\n    name: str\n    price: Decimal\n\nclass OrderItemBaseSchema(BaseModel):\n    id: int\n    order_id: int\n    product_id: int\n    quantity: int\n\nclass UserProfileBaseSchema(BaseModel):\n    id: int\n    user_id: int\n    bio: str\n    avatar_url: str | None = None\n\nclass CategoryBaseSchema(BaseModel):\n    id: int\n    name: str\n    description: str | None = None\n\n# Main model classes (inherit from base schemas, include relationships)\nclass User(UserBaseSchema):\n    # One-to-many: A user can have multiple orders\n    orders: list[Order] | None = Field(default=None)\n\n    # One-to-one: A user has one profile (if profile table exists)\n    profile: UserProfile | None = Field(default=None)\n\nclass Order(OrderBaseSchema):\n    # Many-to-one: Each order belongs to one user\n    user: User | None = Field(default=None)\n\n    # One-to-many: An order can have multiple items\n    order_items: list[OrderItem] | None = Field(default=None)\n\nclass Product(ProductBaseSchema):\n    # One-to-many: A product can be in multiple order items\n    order_items: list[OrderItem] | None = Field(default=None)\n\n    # Many-to-many: A product can have multiple categories\n    categories: list[Category] | None = Field(default=None)\n\nclass OrderItem(OrderItemBaseSchema):\n    # Many-to-one: Each item belongs to one order\n    order: Order | None = Field(default=None)\n\n    # Many-to-one: Each item is for one product\n    product: Product | None = Field(default=None)\n\nclass UserProfile(UserProfileBaseSchema):\n    # One-to-one: Profile belongs to one user\n    user: User | None = Field(default=None)\n\nclass Category(CategoryBaseSchema):\n    # Many-to-many: A category can have multiple products\n    products: list[Product] | None = Field(default=None)\n</code></pre>"},{"location":"examples/singular-class-names/#why-this-approach","title":"Why This Approach?","text":"<ol> <li>Natural Language: Field names read like natural English</li> <li>\u2705 <code>user.orders</code> (user has orders)</li> <li> <p>\u274c <code>user.order</code> (doesn't make semantic sense for collections)</p> </li> <li> <p>Developer Expectations: Follows common ORM conventions</p> </li> <li>Plural fields suggest collections/arrays</li> <li> <p>Singular fields suggest single objects</p> </li> <li> <p>Type Safety: Field names match their type hints</p> </li> <li><code>orders: list[Order]</code> (plural name, list type)</li> <li> <p><code>user: User</code> (singular name, single object type)</p> </li> <li> <p>Database Relationships: Reflects actual database cardinality</p> </li> <li>One-to-many foreign keys naturally create collections</li> <li>Many-to-one foreign keys reference single entities</li> </ol>"},{"location":"examples/singular-class-names/#backward-compatibility","title":"Backward Compatibility","text":"<p>The <code>--singular-names</code> flag is completely optional and defaults to <code>False</code>, ensuring:</p> <ul> <li>No breaking changes for existing users</li> <li>Explicit opt-in behavior</li> <li>Consistent results when not specified</li> </ul>"},{"location":"examples/singular-class-names/#advanced-usage","title":"Advanced Usage","text":""},{"location":"examples/singular-class-names/#combining-with-other-options","title":"Combining with Other Options","text":"<pre><code># Generate singular names with SQLAlchemy models\nsupabase-pydantic gen \\\n  --db-url \"postgresql://user:pass@localhost/mydb\" \\\n  --singular-names \\\n  --type sqlalchemy\n\n# Generate singular names for specific schemas\nsupabase-pydantic gen \\\n  --db-url \"postgresql://user:pass@localhost/mydb\" \\\n  --singular-names \\\n  --schema public \\\n  --schema api\n\n# Generate singular names without CRUD models\nsupabase-pydantic gen \\\n  --db-url \"postgresql://user:pass@localhost/mydb\" \\\n  --singular-names \\\n  --no-crud-models\n</code></pre>"},{"location":"examples/singular-class-names/#best-practices","title":"Best Practices","text":""},{"location":"examples/singular-class-names/#1-be-consistent","title":"1. Be Consistent","text":"<p>Choose either singular or plural class names for your entire project. Mixing both can be confusing.</p>"},{"location":"examples/singular-class-names/#2-consider-your-team","title":"2. Consider Your Team","text":"<p>Make sure your team agrees on the naming convention before implementing it across your codebase.</p>"},{"location":"examples/singular-class-names/#3-update-documentation","title":"3. Update Documentation","text":"<p>If you switch to singular names, update your API documentation and code comments accordingly.</p>"},{"location":"examples/singular-class-names/#4-test-thoroughly","title":"4. Test Thoroughly","text":"<p>When migrating existing code to use singular names, ensure all references are updated and tests pass.</p>"},{"location":"examples/singular-class-names/#troubleshooting","title":"Troubleshooting","text":""},{"location":"examples/singular-class-names/#irregular-plurals","title":"Irregular Plurals","text":"<p>The singularization uses the <code>inflection</code> library, which handles most English pluralization rules correctly:</p> <ul> <li><code>categories</code> \u2192 <code>category</code></li> <li><code>companies</code> \u2192 <code>company</code> </li> <li><code>people</code> \u2192 <code>person</code></li> <li><code>children</code> \u2192 <code>child</code></li> </ul>"},{"location":"examples/singular-class-names/#edge-cases","title":"Edge Cases","text":"<p>For unusual table names or non-English words, the singularization might not work as expected. In such cases, consider:</p> <ol> <li>Renaming the table if possible</li> <li>Using the default plural class names</li> <li>Manually editing the generated code (though this isn't recommended for maintainability)</li> </ol>"},{"location":"examples/singular-class-names/#mixed-naming-conventions","title":"Mixed Naming Conventions","text":"<p>If your database has both singular and plural table names, the <code>--singular-names</code> flag will attempt to singularize all names, which might result in some odd transformations for already-singular tables.</p>"},{"location":"examples/singular-class-names/#migration-guide","title":"Migration Guide","text":"<p>If you're migrating from plural to singular class names:</p> <ol> <li>Generate new models with <code>--singular-names</code></li> <li>Update all imports in your codebase</li> <li>Update type hints and variable declarations</li> <li>Run your test suite to catch any missed references</li> <li>Update API documentation if applicable</li> </ol> <p>Remember: This is a breaking change that will require code updates throughout your application.</p>"},{"location":"examples/sqlalchemy-models/","title":"Working with SQLAlchemy Models","text":"<p>This guide demonstrates how to generate and use SQLAlchemy models with <code>supabase-pydantic</code>. The SQLAlchemy generator creates comprehensive ORM models that include Insert and Update variants for better type safety and validation.</p>"},{"location":"examples/sqlalchemy-models/#prerequisites","title":"Prerequisites","text":"<p>You will need to have:</p> <ul> <li>Python 3.10 or higher</li> <li>A Supabase project or PostgreSQL database</li> <li>The <code>supabase-pydantic</code> package installed</li> </ul>"},{"location":"examples/sqlalchemy-models/#generating-sqlalchemy-models","title":"Generating SQLAlchemy Models","text":"<p>To generate SQLAlchemy models from your database:</p> <pre><code>$ sb-pydantic gen --type sqlalchemy --local\n</code></pre> <p>Or with a database URL:</p> <pre><code>$ sb-pydantic gen --type sqlalchemy --db-url postgresql://postgres:postgres@127.0.0.1:54322/postgres\n</code></pre>"},{"location":"examples/sqlalchemy-models/#customizing-output","title":"Customizing Output","text":"<p>You can customize the output directory and specify schemas:</p> <pre><code>$ sb-pydantic gen --type sqlalchemy --local --dir ./my_models --schema public --schema auth\n</code></pre>"},{"location":"examples/sqlalchemy-models/#generated-model-structure","title":"Generated Model Structure","text":"<p>The SQLAlchemy generator creates three types of models for each table:</p> <ol> <li>Base Models: Complete table representation</li> <li>Insert Models: For creating new records</li> <li>Update Models: For modifying existing records</li> </ol>"},{"location":"examples/sqlalchemy-models/#example-output","title":"Example Output","text":"<p>For a table like <code>users</code>:</p> <pre><code>from __future__ import annotations\nfrom sqlalchemy import ForeignKey, Integer, String\nfrom sqlalchemy.dialects.postgresql import UUID, TIMESTAMP\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship\n\nclass Base(DeclarativeBase):\n    \"\"\"Declarative Base Class.\"\"\"\n    pass\n\nclass User(Base):\n    \"\"\"User base class.\"\"\"\n\n    # Class for table: users\n\n    # Primary Keys\n    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n\n    # Columns\n    email: Mapped[str | None] = mapped_column(String, nullable=True)\n    name: Mapped[str] = mapped_column(String)\n    organization_id: Mapped[UUID4] = mapped_column(UUID(as_uuid=True), ForeignKey(\"organizations.id\"))\n\n    # Relationships\n    organization: Mapped[Organization] = relationship(\"Organization\", back_populates=\"users\")\n\n    # Table Args\n    __table_args__ = (\n        { 'schema': 'public' }\n    )\n\nclass UserInsert(Base):\n    \"\"\"User Insert model.\"\"\"\n\n    # Use this model for inserting new records into users table.\n    # Auto-generated and identity fields are excluded.\n    # Fields with defaults are optional.\n    # Primary key field(s): id\n    # Required fields: id, name, organization_id\n\n    # Primary Keys\n    id: Mapped[int] = mapped_column(Integer)\n\n    # Columns\n    email: Mapped[str | None] = mapped_column(String, nullable=True)\n    name: Mapped[str] = mapped_column(String)\n    organization_id: Mapped[UUID4] = mapped_column(UUID(as_uuid=True))\n\n    # Relationships\n    organization: Mapped[Organization] = relationship(\"Organization\", back_populates=\"users\")\n\nclass UserUpdate(Base):\n    \"\"\"User Update model.\"\"\"\n\n    # Use this model for updating existing records in users table.\n    # All fields are optional to support partial updates.\n    # Primary key field(s) should be used to identify records: id\n\n    # Primary Keys\n    id: Mapped[int | None] = mapped_column(Integer, nullable=True)\n\n    # Columns\n    email: Mapped[str | None] = mapped_column(String, nullable=True)\n    name: Mapped[str | None] = mapped_column(String, nullable=True)\n    organization_id: Mapped[UUID4 | None] = mapped_column(UUID(as_uuid=True), nullable=True)\n\n    # Relationships\n    organization: Mapped[Organization | None] = relationship(\"Organization\", back_populates=\"users\")\n</code></pre>"},{"location":"examples/sqlalchemy-models/#key-features","title":"Key Features","text":""},{"location":"examples/sqlalchemy-models/#1-base-models","title":"1. Base Models","text":"<ul> <li>Complete representation of table structure</li> <li>Proper handling of primary keys</li> <li>Relationship definitions with back-populates</li> <li>Table arguments including schema</li> </ul>"},{"location":"examples/sqlalchemy-models/#2-insert-models","title":"2. Insert Models","text":"<ul> <li>Designed for creating new records</li> <li>Required fields remain required</li> <li>Auto-generated fields are optional</li> <li>Clear documentation about primary keys and required fields</li> </ul>"},{"location":"examples/sqlalchemy-models/#3-update-models","title":"3. Update Models","text":"<ul> <li>All fields are optional to support partial updates</li> <li>Primary key fields are included but nullable</li> <li>Maintains relationship definitions</li> <li>Optimized for PATCH/PUT operations</li> </ul>"},{"location":"examples/sqlalchemy-models/#using-sqlalchemy-models-with-fastapi","title":"Using SQLAlchemy Models with FastAPI","text":"<p>Here's an example of using these models with FastAPI and SQLAlchemy:</p> <pre><code>from fastapi import FastAPI, Depends, HTTPException\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy.ext.asyncio import AsyncSession, create_async_engine\nfrom sqlalchemy.ext.asyncio import async_sessionmaker\n\nfrom .models import User, UserInsert, UserUpdate\nfrom .database import get_db\n\napp = FastAPI()\n\n@app.post(\"/users/\", response_model=User)\nasync def create_user(user: UserInsert, db: AsyncSession = Depends(get_db)):\n    db_user = User(\n        name=user.name,\n        email=user.email,\n        organization_id=user.organization_id\n    )\n    db.add(db_user)\n    await db.commit()\n    await db.refresh(db_user)\n    return db_user\n\n@app.patch(\"/users/{user_id}\", response_model=User)\nasync def update_user(user_id: int, user_update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    db_user = await db.get(User, user_id)\n    if not db_user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    user_data = user_update.model_dump(exclude_unset=True)\n    for key, value in user_data.items():\n        if value is not None:  # Only update provided fields\n            setattr(db_user, key, value)\n\n    await db.commit()\n    await db.refresh(db_user)\n    return db_user\n\n@app.get(\"/users/{user_id}\", response_model=User)\nasync def read_user(user_id: int, db: AsyncSession = Depends(get_db)):\n    db_user = await db.get(User, user_id)\n    if db_user is None:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return db_user\n</code></pre>"},{"location":"examples/sqlalchemy-models/#best-practices","title":"Best Practices","text":"<ol> <li>Use Type-Specific Models:</li> <li>Use base models for queries and responses</li> <li>Use Insert models for creation operations</li> <li> <p>Use Update models for modification operations</p> </li> <li> <p>Partial Updates:</p> </li> <li>Use <code>model_dump(exclude_unset=True)</code> to only include fields that were explicitly set</li> <li> <p>Only update non-None values to preserve existing data</p> </li> <li> <p>Relationship Handling:</p> </li> <li>Consider using dedicated endpoints for managing relationships</li> <li> <p>Be careful with cascading operations</p> </li> <li> <p>Database Migrations:</p> </li> <li>Use Alembic for schema migrations</li> <li>Keep generated models in sync with your database schema</li> </ol>"},{"location":"examples/sqlalchemy-models/#advanced-usage","title":"Advanced Usage","text":""},{"location":"examples/sqlalchemy-models/#custom-validation","title":"Custom Validation","text":"<p>You can extend the generated models with custom validation:</p> <pre><code>from sqlalchemy.orm import validates\n\nclass User(Base):\n    # ... existing code ...\n\n    @validates('email')\n    def validate_email(self, key, email):\n        if email and '@' not in email:\n            raise ValueError(\"Invalid email format\")\n        return email\n</code></pre>"},{"location":"examples/sqlalchemy-models/#adding-business-logic","title":"Adding Business Logic","text":"<p>Extend the models with business logic methods:</p> <pre><code>class User(Base):\n    # ... existing code ...\n\n    def is_admin(self):\n        return self.role == 'admin'\n\n    def get_full_name(self):\n        return f\"{self.first_name} {self.last_name}\"\n</code></pre>"},{"location":"examples/sqlalchemy-models/#conclusion","title":"Conclusion","text":"<p>The SQLAlchemy model generator in <code>supabase-pydantic</code> provides a comprehensive solution for interacting with your database using modern SQLAlchemy features. The specialized Insert and Update models ensure type safety while maintaining flexibility for different database operations.</p>"},{"location":"getting-started/changelog/","title":"CHANGELOG","text":""},{"location":"getting-started/changelog/#v0262-2025-10-17","title":"v0.26.2 (2025-10-17)","text":""},{"location":"getting-started/changelog/#fix","title":"Fix","text":"<ul> <li> <p>fix: semantic release build cmd (#119) (<code>e94c34a</code>)</p> </li> <li> <p>fix: python build command in semantic release (#118) (<code>5066162</code>)</p> </li> <li> <p>fix: incorrect table child table types and singularize bug &amp; semantic versioning errors (#117)</p> </li> <li> <p>fix: singularization and incorrect collection checking</p> </li> <li> <p>test: update tests</p> </li> <li> <p>chore: update changelog</p> </li> <li> <p>fix: update semantic release configuration to resolve changelog generation (<code>d4f8489</code>)</p> </li> </ul>"},{"location":"getting-started/changelog/#v0261-2025-09-29","title":"v0.26.1 (2025-09-29)","text":""},{"location":"getting-started/changelog/#fix_1","title":"Fix","text":"<ul> <li>fix: extend JSON field types to support list[dict] and list[Any] variants (#115) (<code>f64d600</code>)</li> </ul>"},{"location":"getting-started/changelog/#v0260-2025-09-26","title":"v0.26.0 (2025-09-26)","text":""},{"location":"getting-started/changelog/#feature","title":"Feature","text":"<ul> <li> <p>feat: add ability to singularize class names (#113)</p> </li> <li> <p>feat: add option to singularize class names</p> </li> <li> <p>docs: add guide for using singular class names</p> </li> <li> <p>test: add singular_names flag support to gen command tests</p> </li> <li> <p>feat: pass singular_names parameter to writer instances for consistent naming; add integration tests</p> </li> <li> <p>fix: pass singular_names to base writer to ensure consistent class naming</p> </li> <li> <p>test: add support for --no-crud-models flag in singular names test</p> </li> <li> <p>test: fix for tox</p> </li> <li> <p>test: remove test for later (<code>73cd6cf</code>)</p> </li> </ul>"},{"location":"getting-started/changelog/#v0257-2025-09-24","title":"v0.25.7 (2025-09-24)","text":""},{"location":"getting-started/changelog/#fix_2","title":"Fix","text":"<ul> <li> <p>fix: modify enum type generation and views in schema marshaling to be namespace independent (#111)</p> </li> <li> <p>fix: modify enum type generation and views in schema marshaling to be namespace independent</p> </li> <li> <p>docs: add changelog entries for v0.25.0 through v0.25.6 releases</p> </li> <li> <p>fix: inverted flag logic (<code>1b25af7</code>)</p> </li> </ul>"},{"location":"getting-started/changelog/#v0256-2025-09-18","title":"v0.25.6 (2025-09-18)","text":""},{"location":"getting-started/changelog/#documentation","title":"Documentation","text":"<ul> <li>docs: add PyPI monthly downloads badge to README (#109) (<code>81f910a</code>)</li> </ul>"},{"location":"getting-started/changelog/#v0255-2025-09-18","title":"v0.25.5 (2025-09-18)","text":""},{"location":"getting-started/changelog/#fix_3","title":"Fix","text":"<ul> <li>fix: add missing decimal import for numeric and float types in SQLAlchemy type maps (#108) (<code>34cc805</code>)</li> </ul>"},{"location":"getting-started/changelog/#v0254-2025-09-18","title":"v0.25.4 (2025-09-18)","text":""},{"location":"getting-started/changelog/#fix_4","title":"Fix","text":"<ul> <li>fix: update datetime type references to use fully qualified paths (#107) (<code>ab87c48</code>)</li> </ul>"},{"location":"getting-started/changelog/#v0253-2025-09-17","title":"v0.25.3 (2025-09-17)","text":""},{"location":"getting-started/changelog/#fix_5","title":"Fix","text":"<ul> <li>fix: add proper datetime imports and handle timezone columns in SQLAlchemy schema generation (#106) (<code>a99c5f1</code>)</li> </ul>"},{"location":"getting-started/changelog/#v0252-2025-09-16","title":"v0.25.2 (2025-09-16)","text":""},{"location":"getting-started/changelog/#fix_6","title":"Fix","text":"<ul> <li>fix(types): add missing imports for array element types (#104) (<code>fce553c</code>)</li> </ul>"},{"location":"getting-started/changelog/#v0251-2025-09-14","title":"v0.25.1 (2025-09-14)","text":""},{"location":"getting-started/changelog/#fix_7","title":"Fix","text":"<ul> <li> <p>fix: enhance enum handling and naming (#103)</p> </li> <li> <p>fix: enhance enum handling and logging for PostgreSQL array types</p> </li> <li> <p>fix: improve error handling and logging in ruff formatting process</p> </li> <li> <p>fix: add support for column comments in MySQL schema marshaler</p> </li> <li> <p>fix: correct warning message in ruff formatting test (<code>1a1fbaa</code>)</p> </li> </ul>"},{"location":"getting-started/changelog/#v0250-2025-09-14","title":"v0.25.0 (2025-09-14)","text":""},{"location":"getting-started/changelog/#feature_1","title":"Feature","text":"<ul> <li> <p>feat: add descriptions to Pydantic field types and future support Python 3.14 (#102)</p> </li> <li> <p>feat: added support for getting column description from postgres and mysql</p> </li> <li> <p>refactor: add Python 3.14 support, fix tests, update CHANGELOG</p> </li> <li> <p>fix: escape quotes in column description to prevent syntax errors</p> </li> <li> <p>test: add unit test for column descriptions in Pydantic fields with escaping</p> </li> </ul> <p>Co-authored-by: Adri\u00e1n Gallego Castellanos &lt;kugoad@gmail.com&gt; (<code>f9c7b20</code>)</p>"},{"location":"getting-started/changelog/#v0242-2025-08-26","title":"v0.24.2 (2025-08-26)","text":""},{"location":"getting-started/changelog/#chore","title":"Chore","text":"<ul> <li>chore: align mysql-connector for conda (#100) (<code>846449e</code>)</li> </ul>"},{"location":"getting-started/changelog/#v0241-2025-08-26","title":"v0.24.1 (2025-08-26)","text":""},{"location":"getting-started/changelog/#documentation_1","title":"Documentation","text":"<ul> <li>docs: update README (#99) (<code>143964e</code>)</li> </ul>"},{"location":"getting-started/changelog/#v0240-2025-08-26","title":"v0.24.0 (2025-08-26)","text":""},{"location":"getting-started/changelog/#feature_2","title":"Feature","text":"<ul> <li> <p>feat: add mysql support (#98)</p> </li> <li> <p>chore: housekeeping</p> </li> <li> <p>feat: add types-pymysql</p> </li> <li> <p>feat: implement database, connector, and marshaling abstraction with PostgreSQL, working version</p> </li> <li> <p>refactor: reorganize postgres-specific code into dedicated drivers directory</p> </li> <li> <p>feat: first working version of mysql connector</p> </li> <li> <p>refactor: correct python typing for mysql generation</p> </li> <li> <p>chore: mypy cleanup</p> </li> <li> <p>chore: mypy fixes</p> </li> <li> <p>test: correct test startup errors</p> </li> <li> <p>test: fix failing tests</p> </li> <li> <p>test: add new tests for increased coverage</p> </li> <li> <p>test: increase coverage to above threshold</p> </li> <li> <p>test: finalize testing</p> </li> <li> <p>refactor: improve logging</p> </li> <li> <p>chore: correct type issue</p> </li> <li> <p>refactor: resolution of connection parameters</p> </li> <li> <p>fix: misleading warning messages</p> </li> <li> <p>test: fix tests</p> </li> <li> <p>fix: incorrect mapping by database type</p> </li> <li> <p>fix: issue-84</p> </li> <li> <p>refactor: log time fmt</p> </li> <li> <p>docs: update docs</p> </li> <li> <p>feat: add vulture</p> </li> <li> <p>docs: cleanup</p> </li> <li> <p>docs: fix link</p> </li> <li> <p>chore: vulture changes</p> </li> <li> <p>refactor: ignore whitelist (<code>0a27a58</code>)</p> </li> </ul>"},{"location":"getting-started/changelog/#v0230-2025-08-18","title":"v0.23.0 (2025-08-18)","text":""},{"location":"getting-started/changelog/#feature_3","title":"Feature","text":"<ul> <li>feat: add sqlalchemy generator (#96)</li> </ul> <p> ... and so on. For the full changelog, please see the releases page.</p>"},{"location":"getting-started/contributing/","title":"Contributing","text":"<p>We welcome contributions and volunteers for the project! Please read the following guidelines before contributing.</p>"},{"location":"getting-started/contributing/#issues","title":"Issues","text":"<p>Questions, bug reports, and feature requests are welcome as discussions or issues. Please search the existing issues before opening a new one. To report a security vulneratbility, please see the security policy.</p> <p>To help us resolve your issue, please provide the following information:</p> <ul> <li>Expected behavior: A clear and concise description of what you expected to happen.</li> <li>Actual behavior: A clear and concise description of what actually happened.</li> <li>Steps to reproduce: How can we reproduce the issue?</li> <li>Environment: Include relevant details like the operating system, Python version, and any other relevant information.</li> </ul>"},{"location":"getting-started/contributing/#pull-requests","title":"Pull Requests","text":"<p>We welcome pull requests for bug fixes, new features, and improvements. We aim to provide feedback regularly and will review your pull request as soon as possible. </p> <p>Unless your change is not trivial, please create an issue before submitting a pull request. This will allow us to discuss the change and ensure it aligns with the project goals.</p>"},{"location":"getting-started/contributing/#prerequisites","title":"Prerequisites","text":"<p>You will need the following to start developing:</p> <ul> <li>Python 3.10+</li> <li>virtualenv, poetry, or pipenv for the development environment.</li> <li>git for version control.</li> <li>make for running the Makefile commands.</li> </ul>"},{"location":"getting-started/contributing/#installation-setup","title":"Installation &amp; Setup","text":"<p>Fork the repository on GitHub and clone your fork locally. Then, install the dependencies:</p> <pre><code># Clone your fork and cd into the repo directory\ngit clone git@github.com:&lt;your username&gt;/supabase-pydantic.git\ncd supabase-pydantic\n\n# Install the dependencies\n# e.g., using poetry\npoetry install\n\n# Setup pre-commit\nmake pre-commit-setup\n</code></pre>"},{"location":"getting-started/contributing/#checkout-a-new-branch","title":"Checkout a New Branch","text":"<p>Create a new branch for your changes:</p> <pre><code># Create a new branch\ngit checkout -b my-new-feature\n</code></pre>"},{"location":"getting-started/contributing/#run-tests-linting-formatting-type-checking-pre-commit-hooks","title":"Run Tests, Linting, Formatting, Type checking, &amp; Pre-Commit Hooks","text":"<p>Before submitting a pull request, ensure that the tests pass, the code is formatted correctly, and the code passes the linting and type checking checks:</p> <pre><code># Run tests\nmake test\n\n# Run linting &amp; formatting\nmake lint\nmake format\nmake check-types\n\n# Run pre-commit hooks\nmake pre-commit\n</code></pre>"},{"location":"getting-started/contributing/#build-documentation","title":"Build Documentation","text":"<p>If you make changes to the documentation, you can build the documentation locally:</p> <pre><code># Build the documentation\nmake serve-docs\n</code></pre>"},{"location":"getting-started/contributing/#commit-and-push-your-changes","title":"Commit and Push your Changes","text":"<p>Commit your changes, push to your forked repository, and create a pull request:</p> <p>Please follow the pull request template and fill in as much information as possible. Link to any relevant issues and include a description of your changes.</p> <p>When your pull request is ready for review, add a comment with the message \"please review\" and we'll take a look as soon as we can.</p>"},{"location":"getting-started/contributing/#code-style-conventions","title":"Code Style &amp; Conventions","text":""},{"location":"getting-started/contributing/#documentation-style","title":"Documentation Style","text":"<p>Documentation is written in format and follows the Markdown Style Guide. Please ensure that the documentation is clear, concise, and easy to read. API documentation is generated using mkdocs &amp; mkdocstrings. We follow google-style docstrings.</p>"},{"location":"getting-started/contributing/#code-documentation","title":"Code Documentation","text":"<p>Please ensure that the code is well-documented and easy to understand when contributing. The following should be documented using proper docstrings:</p> <ul> <li>Modules</li> <li>Class Definitions</li> <li>Function Definitions</li> <li>Module-level Variables</li> </ul> <p><code>supabase-pydantic</code> uses Google-style docstrings according to PEP 257. Please see the example for more information.</p> <p>Class attributes and function arguments should be documented in the style of \"name: description\" &amp; include an annotated type and return type when applicable. Feel free to include example code in docstrings. </p>"},{"location":"getting-started/getting-help/","title":"Getting help with supabase-pydantic","text":""},{"location":"getting-started/getting-help/#have-an-issue","title":"Have an issue?","text":"<p>If you have any issues with supabase-pydantic, feel free to open an issue. However, please understand that this is a growing project and I may not be able to address all issues immediately or monitor as actively as a full time maintainer or team.</p>"},{"location":"getting-started/getting-help/#need-help","title":"Need help?","text":"<p>The API documents &amp; examples are the best source reference documentation for supabase-pydantic.</p>"},{"location":"getting-started/getting-help/#stack-overflow","title":"Stack Overflow","text":"<p>If you have a question about how to use supabase-pydantic, please ask on Stack Overflow. Tag your question with <code>supabase-pydantic</code> so that the community can see it.</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>To install the package, you can use the following command:</p> <pre><code>pip install supabase-pydantic\n</code></pre> <p>There are a few evolving dependencies that will need to be installed as well &amp; to take note of:</p> <ul> <li>pydantic-v2: A data validation and settings management using Python type annotations. We may integrate for v1 in the future.</li> <li>psycopg2-binary: A PostgreSQL database adapter for Python. We will likely integrate a more robust adapter in the future, possibly integrating the lower-level asyncpg or golang client with Supabase. Other database connections will be added in the future as well.</li> <li>types-psycopg2: Type hints for psycopg2.</li> <li>faker: A Python package that generates fake data. This package will be critical for adding a future feature to generate seed data.</li> </ul> <p>If you have Python 3.10+ installed, you should be fine, but please report any issues you encounter.</p> <p>The package is also available on conda under the conda-forge channel: </p> <pre><code>conda install -c conda-forge supabase-pydantic\n</code></pre>"},{"location":"getting-started/installation/#install-from-source","title":"Install from source","text":"<p>To install the package from source, you can use the following command:</p> <pre><code>pip install git+https://github.com/kmbhm1/supabase-pydantic.git@main\n</code></pre>"},{"location":"getting-started/security/","title":"Security Policy","text":"<p>If you discover a security issue, please bring it to our attention right away!</p>"},{"location":"getting-started/security/#supported-versions","title":"Supported Versions","text":"<p>Project versions that are currently being supported with security updates vary per project. Please see specific project repositories for details. If nothing is specified, only the latest major versions are supported.</p>"},{"location":"getting-started/security/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>Please DO NOT file a public issue to report a security vulberability, instead send your report privately to @kmbhm1. This will help ensure that any vulnerabilities that are found can be disclosed responsibly to any affected parties.</p>"},{"location":"getting-started/welcome/","title":"Supabase Pydantic","text":"<p>Supabase Pydantic is a Python library that generates Pydantic models for Supabase - more models &amp; database support to come .  It is designed to enhance the utility of Supabase as an entity for rapid prototyping and development. </p> A First Example<pre><code>$ sb-pydantic gen --type pydantic --framework fastapi --local\n\n2023-09-12 14:30:15 - INFO - PostgreSQL connection opened successfully\n2023-09-12 14:30:17 - INFO - Processing schema: public\n2023-09-12 14:30:19 - INFO - PostgreSQL connection closed successfully\n2023-09-12 14:30:20 - INFO - Generating FastAPI Pydantic models...\n2023-09-12 14:30:22 - INFO - FastAPI Pydantic models generated successfully: /path/to/your/project/entities/fastapi/schemas_latest.py\n2023-09-12 14:30:23 - INFO - File formatted successfully: /path/to/your/project/entities/fastapi/schemas_latest.py\n</code></pre> <p>Some users may find it more convenient to integrate a Makefile command:</p> Makefile<pre><code>gen-types:\n    @echo \"Generating FastAPI Pydantic models...\"\n    @sb-pydantic gen --type pydantic --framework fastapi --dir &lt;your path&gt; --local\n</code></pre>"},{"location":"getting-started/welcome/#why-use-supabase-pydantic","title":"Why use supabase-pydantic?","text":"<p>The supabase-py library currently lacks an automated system to enhance type safety and data validation in Python\u2014a similar, but essential feature that is readily available and highly useful in the JavaScript/TypeScript library, as outlined in Supabase's documentation.</p> <p>Pydantic, a popular library for data validation and settings management in Python, leverages type annotations to validate data, significantly enhancing the robustness and clarity of code. While both TypeScript and Pydantic aim to improve type safety and structure within dynamic programming environments, a key distinction is that Pydantic validates data at runtime.</p> <p>This package aims to bridge the gap, delivering an enriched experience for Python developers with Supabase. It not only replicates the functionalities of the TypeScript library but is also finely tuned to the diverse tools and landscape of the Python community. Moreover, it's designed to turbocharge your workflow, making rapid prototyping not just faster but also a delightful adventure in development.</p>"},{"location":"getting-started/welcome/#the-bennies","title":"The Bennies","text":"<ol> <li> <p>Automated enhanced type safety: supabase-pydantic generates Pydantic models for Supabase without the hassle of manual setup, ensuring that your data is validated and structured correctly, requiring less oversight. This feature significantly enhances the robustness of deployment pipelines and clarity of your code, making it easier for you to focus on building your application.</p> </li> <li> <p>Rapid prototyping: With supabase-pydantic, you can quickly generate FastAPI Pydantic models, saving you time and effort in setting up your project's schemas, models, etc.</p> </li> <li> <p>Seamless integration: supabase-pydantic is intended to integrate seamlessly with development and automated pipelines, allowing you to leverage the power of Supabase while enjoying the benefits of Pydantic's data validation and settings management in a streamlined fashion.</p> </li> <li> <p>Pythonic experience: Built specifically for the Python community, supabase-pydantic is finely tuned to the tools and landscape of Python development, providing a familiar and efficient workflow.</p> </li> <li> <p>Comprehensive documentation: supabase-pydantic comes with comprehensive documentation, making it easy to get started and explore its features.</p> </li> </ol>"}]}